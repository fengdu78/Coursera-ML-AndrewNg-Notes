1
00:00:00,200 --> 00:00:01,770
By now you've seen the anomaly
在此之前 你已经学习了
(字幕整理：中国海洋大学 黄海广,haiguang2000@qq.com )

2
00:00:02,250 --> 00:00:03,540
detection algorithm and we've
异常检测算法 并且

3
00:00:03,740 --> 00:00:05,240
also talked about how to
我们也讨论了如何

4
00:00:05,570 --> 00:00:06,870
evaluate an anomaly detection
评估一个异常检测算法

5
00:00:07,330 --> 00:00:08,880
algorithm. It turns out,
事实上

6
00:00:09,530 --> 00:00:10,800
that when you're applying anomaly
当你应用异常检测时

7
00:00:11,170 --> 00:00:12,400
detection, one of the
对它的效率

8
00:00:12,460 --> 00:00:13,290
things that has a huge
影响最大的

9
00:00:13,720 --> 00:00:14,860
effect on how well it
因素之一是

10
00:00:14,940 --> 00:00:16,440
does, is what features you
你使用什么特征变量

11
00:00:16,520 --> 00:00:17,720
use, and what features you choose,
你选择什么特征变量

12
00:00:18,530 --> 00:00:19,910
to give the anomaly detection algorithm.
来输入异常检测算法

13
00:00:20,830 --> 00:00:22,170
So in this video, what I'd
那么 在本视频中

14
00:00:22,280 --> 00:00:23,390
like to do is say a few
我将要做的事情就是

15
00:00:23,480 --> 00:00:24,890
words, give some suggestions and
给你们一些建议

16
00:00:25,000 --> 00:00:26,250
guidelines for how to
关于如何设计或选择

17
00:00:26,370 --> 00:00:27,920
go about designing or selecting
异常检测算法的

18
00:00:28,470 --> 00:00:30,950
features give to an anomaly detection algorithm.
特征变量

19
00:00:33,920 --> 00:00:35,310
In our anomaly detection algorithm,
在我们的异常检测算法中

20
00:00:36,120 --> 00:00:37,270
one of the things we did was
我们做的事情之一就是

21
00:00:37,510 --> 00:00:40,330
model the features using this sort of Gaussian distribution.
使用这种正态(高斯)分布来对特征向量建模

22
00:00:41,180 --> 00:00:42,810
With xi to mu
就是有 xi 服从正态分布 期望为μi

23
00:00:43,120 --> 00:00:46,050
i, sigma squared i, lets say.
方差为 σi 平方

24
00:00:46,550 --> 00:00:47,890
And so one thing that
那么 我常做的一件事

25
00:00:47,950 --> 00:00:49,620
I often do would be to plot the
就是画出这些数据

26
00:00:50,670 --> 00:00:52,260
data or the histogram of
或者用直方图表示数据

27
00:00:52,330 --> 00:00:53,490
the data, to make sure that
以确保

28
00:00:53,940 --> 00:00:55,210
the data looks vaguely
这些数据在

29
00:00:55,540 --> 00:00:57,320
Gaussian before feeding it
应用我的异常检测算法前

30
00:00:57,470 --> 00:00:58,830
to my anomaly detection algorithm.
看起来像高斯分布

31
00:00:59,810 --> 00:01:01,040
And, it'll usually work okay,
当然即使你的数据并不是高斯分布

32
00:01:01,610 --> 00:01:02,820
even if your data isn't Gaussian,
它也基本上可以良好地运行

33
00:01:03,400 --> 00:01:05,700
but this is sort of a nice sanitary check to run.
它也基本上可以良好地运行

34
00:01:05,970 --> 00:01:06,860
And by the way, in case your data
如果你的数据

35
00:01:07,400 --> 00:01:09,540
looks non-Gaussian, the algorithms will often work just find.
看起来不像正态分布 算法也常常可以正常运行

36
00:01:10,410 --> 00:01:12,070
But, concretely if I
但是具体而言

37
00:01:12,430 --> 00:01:13,510
plot the data like this,
我将数据画成这样

38
00:01:13,850 --> 00:01:15,280
and if it looks like a histogram like
如果它的柱状图看起来

39
00:01:15,370 --> 00:01:16,480
this, and the way
像这样 另外说一下

40
00:01:16,630 --> 00:01:17,800
to plot a histogram is to
画柱状图的方法是

41
00:01:17,950 --> 00:01:19,910
use the HIST, or the
使用 hist 命令

42
00:01:20,130 --> 00:01:21,820
HIST command in Octave,
就是 Octave 里面的 hist 命令

43
00:01:21,910 --> 00:01:22,800
but it looks like this, this looks
但看起来好像

44
00:01:23,010 --> 00:01:24,770
vaguely Gaussian, so if
这个图形近似像一个高斯分布

45
00:01:24,940 --> 00:01:26,200
my features look like this,
所以如果我的特征变量是这样的

46
00:01:26,480 --> 00:01:29,970
I would be pretty happy feeding into my algorithm.
那么我可以很高兴地把它们送入我的学习算法了

47
00:01:30,180 --> 00:01:31,830
But if i were to plot a histogram of my
但如果我画出来的

48
00:01:31,950 --> 00:01:33,070
data, and it were
直方图是这样的话

49
00:01:33,210 --> 00:01:34,800
to look like this well, this
好吧

50
00:01:35,060 --> 00:01:36,090
doesn't look at all like a
那么这就看起来完全不像钟形曲线

51
00:01:36,220 --> 00:01:38,430
bell shaped curve, this is a very asymmetric distribution,
这个分布很不对称

52
00:01:39,410 --> 00:01:40,660
it has a peak way off to one side.
它的峰值非常偏向一边

53
00:01:41,750 --> 00:01:42,660
If this is what my data
如果我的数据是这样的话

54
00:01:42,800 --> 00:01:43,960
looks like, what I'll often
通常我要做的事情

55
00:01:44,190 --> 00:01:45,370
do is play with different
是对数据进行一些不同的转换

56
00:01:45,730 --> 00:01:46,920
transformations of the data in order
来确保这些数据

57
00:01:47,010 --> 00:01:48,850
to make it look more Gaussian.
看起来更像高斯分布

58
00:01:49,480 --> 00:01:51,940
And again the algorithm will usually work okay, even if you don't.
虽然通常来说你不这么做 算法也会运行地很好

59
00:01:52,590 --> 00:01:53,660
But if you use these transformations
但如果你使用一些转换方法

60
00:01:54,630 --> 00:01:56,590
to make your data more gaussian, it might work a bit better.
使你的数据更像高斯分布的话 你的算法会工作得更好

61
00:01:58,030 --> 00:01:59,780
So given the data set
所以

62
00:02:00,140 --> 00:02:01,340
that looks like this, what I
如果给我这样的数据集

63
00:02:01,430 --> 00:02:02,810
might do is take a
我通常要做的是

64
00:02:03,010 --> 00:02:04,520
log transformation of the
进行一个求对数的转换

65
00:02:04,660 --> 00:02:05,930
data and if i
如果我这样做的话

66
00:02:06,060 --> 00:02:07,810
do that and re-plot the
重新把直方图画出来

67
00:02:08,150 --> 00:02:09,110
histogram, what I end up
对于这个具体的例子

68
00:02:09,330 --> 00:02:10,500
with in this particular example,
我就会得到

69
00:02:11,130 --> 00:02:12,400
is a histogram that looks like this.
像这样的一个直方图

70
00:02:12,540 --> 00:02:14,470
And this looks much more Gaussian, right?
这样就看起来更像高斯分布了 对吧？

71
00:02:14,650 --> 00:02:15,720
This looks much more like the classic
这看起来就更像

72
00:02:16,690 --> 00:02:18,020
bell shaped curve, that we
典型的钟形曲线

73
00:02:18,710 --> 00:02:21,000
can fit with some mean and variance paramater sigma.
这样我就能拟合出期望和方差参数了

74
00:02:22,180 --> 00:02:22,940
So what I mean by taking
所以这里我说的

75
00:02:23,230 --> 00:02:24,610
a log transform, is really that
进行一个取对数的转换

76
00:02:24,860 --> 00:02:26,140
if I have some feature x1 and
意思是这样的

77
00:02:26,860 --> 00:02:28,260
then the histogram of x1 looks
如果我有一个特征变量 比如 x1

78
00:02:28,720 --> 00:02:30,500
like this then I might
直方图是这样的

79
00:02:31,070 --> 00:02:32,210
take my feature x1
那么我就用 x1 的对数

80
00:02:32,410 --> 00:02:33,890
and replace it with log
log(x1) 来替换掉 x1

81
00:02:34,800 --> 00:02:36,730
of x1 and this is
所以 经过替换

82
00:02:36,860 --> 00:02:37,880
my new x1 that I'll plot
这就是我的新 x1

83
00:02:38,170 --> 00:02:40,000
to the histogram over on the right, and this looks much
我把它的直方图画在右边

84
00:02:40,430 --> 00:02:42,350
more Guassian.
这看起来更像高斯分布了

85
00:02:44,000 --> 00:02:44,730
Rather than just a log transform some other things you can
除了取对数变换之外

86
00:02:44,920 --> 00:02:46,020
do, might be, let's say
还有别的一些方法也可以用

87
00:02:46,110 --> 00:02:47,720
I have a different feature x2,
假如这是另一个特征 x2

88
00:02:48,690 --> 00:02:49,840
maybe I'll replace that will
现在我用 log(x2 + 1) 来取代

89
00:02:50,120 --> 00:02:52,560
log x plus 1,
或者更一般地

90
00:02:52,630 --> 00:02:54,720
or more generally with log
我可以在 x2 后面加上

91
00:02:56,360 --> 00:02:57,690
x with x2 and
某个常数 c

92
00:02:58,430 --> 00:03:00,350
some constant c and this
然后求对数来取代 x2

93
00:03:00,520 --> 00:03:01,540
constant could be something
我会调整这个常数 c 的值

94
00:03:01,890 --> 00:03:04,390
that I play with, to try to make it look as Gaussian as possible.
使得这个分布看起来尽可能地像高斯分布

95
00:03:05,610 --> 00:03:06,820
Or for a different feature x3, maybe
或者对于另一个特征 x3

96
00:03:07,200 --> 00:03:08,610
I'll replace it with x3,
也许我可以用

97
00:03:09,730 --> 00:03:11,250
I might take the square root.
它的平方根来取代

98
00:03:11,610 --> 00:03:14,180
The square root is just x3 to the power of one half, right?
x3 的平方根也就是 x3 的二分之一次方 对吧？

99
00:03:15,260 --> 00:03:16,660
And this one half
而这个 二分之一

100
00:03:17,130 --> 00:03:19,220
is another example of a parameter I can play with.
又是一个可以由我来确定的参数

101
00:03:19,640 --> 00:03:21,600
So, I might have x4 and
所以 或许对另一个特征 x4

102
00:03:22,450 --> 00:03:23,820
maybe I might instead replace
我可以用 x4 的另一个幂次方

103
00:03:24,410 --> 00:03:25,370
that with x4 to the power
来取代 x4

104
00:03:25,730 --> 00:03:26,790
of something else, maybe to the
比如说可以用

105
00:03:26,890 --> 00:03:28,460
power of 1/3.
三分之一次幂

106
00:03:28,940 --> 00:03:30,830
And these, all of
所有这些

107
00:03:30,900 --> 00:03:32,320
these, this one, this
所有这些参数

108
00:03:32,540 --> 00:03:33,670
exponent parameter, or the
这个指数参数

109
00:03:33,810 --> 00:03:35,110
C parameter, all of these
或者这个参数 c

110
00:03:35,380 --> 00:03:36,880
are examples of parameters that
所有这些参数你都可以进行调整

111
00:03:36,960 --> 00:03:38,110
you can play with in order
目的只有一个

112
00:03:38,460 --> 00:03:40,420
to make your data look a little bit more Gaussian.
就是让数据看起来更像高斯分布

113
00:03:45,180 --> 00:03:46,210
So, let me show you a live demo
下面我给你演示一下

114
00:03:46,740 --> 00:03:48,720
of how I actually go about
如何对这些参数进行调整

115
00:03:49,150 --> 00:03:50,690
playing with my data to make it look more Gaussian.
来让我的数据看起来更像高斯分布

116
00:03:51,650 --> 00:03:52,370
So, I have already loaded
这里我已经在 Octave 中

117
00:03:52,750 --> 00:03:54,730
in to octave here a set
加载了一系列特征 x

118
00:03:54,860 --> 00:03:56,170
of features x I have a thousand examples
这里我加载了1000个样本

119
00:03:57,150 --> 00:03:57,870
loaded over there.
这里我加载了1000个样本

120
00:03:58,580 --> 00:04:00,100
So let's pull up the histogram of my data.
所以让我们来画出数据的直方图

121
00:04:01,560 --> 00:04:02,570
Use the hist x command.
使用 hist(x) 命令

122
00:04:03,190 --> 00:04:04,100
So there's my histogram.
这就是我的直方图了

123
00:04:05,660 --> 00:04:06,580
By default, I think this
默认情况下

124
00:04:06,680 --> 00:04:08,250
uses 10 bins of histograms,
直方图有十个柱

125
00:04:08,610 --> 00:04:10,400
but I want to see a more fine grid histogram.
可以重新把样条设置地更好一点

126
00:04:11,330 --> 00:04:12,950
So we do hist to the x, 50,
我们输入 hist(x, 50)

127
00:04:13,050 --> 00:04:14,970
so, this plots it in 50 different bins.
这样就画出了50个柱

128
00:04:15,310 --> 00:04:15,660
Okay, that looks better.
这样看起来好多了

129
00:04:16,180 --> 00:04:18,570
Now, this doesn't look very Gaussian, does it?
但现在看起来还不够"高斯"

130
00:04:18,930 --> 00:04:20,720
So, lets start playing around with the data.
所以下面我们来调整一下参数

131
00:04:20,900 --> 00:04:22,310
Lets try a hist of
首先试试 x 的0.5次方

132
00:04:22,610 --> 00:04:24,810
x to the 0.5.
也就是说

133
00:04:25,090 --> 00:04:26,590
So we take the
我们对数据取平方根

134
00:04:26,870 --> 00:04:28,820
square root of the data, and plot that histogram.
然后画出直方图

135
00:04:30,670 --> 00:04:31,680
And, okay, it looks
好了 现在看起来

136
00:04:31,800 --> 00:04:32,870
a little bit more Gaussian, but not
有那么一点像高斯分布了

137
00:04:32,960 --> 00:04:34,550
quite there, so let's play at the 0.5 parameter.
但还是不够好 我们再调整一下

138
00:04:34,790 --> 00:04:35,330
Let's see.
让我们看一看

139
00:04:36,520 --> 00:04:38,110
Set this to 0.2.
把0.5减小到0.2试试

140
00:04:38,280 --> 00:04:39,780
Looks a little bit more Gaussian.
又更像高斯分布了一点

141
00:04:40,930 --> 00:04:43,150
Let's reduce a little bit more 0.1.
我们再减小一点 试试0.1

142
00:04:44,450 --> 00:04:45,220
Yeah, that looks pretty good.
耶！好极了

143
00:04:45,500 --> 00:04:48,440
I could actually just use 0.1.
所以我可以使用0.1

144
00:04:48,880 --> 00:04:50,190
Well, let's reduce it to 0.05.
我们再试试更小的 0.05

145
00:04:50,520 --> 00:04:50,910
And, you know?
然后 你看

146
00:04:51,740 --> 00:04:52,750
Okay, this looks pretty Gaussian,
这样看起来更像高斯分布了

147
00:04:53,230 --> 00:04:54,090
so I can define a new
因此 我们可以定义一个

148
00:04:54,190 --> 00:04:55,510
feature which is x mu equals
新的特征变量 xNew

149
00:04:56,110 --> 00:04:58,940
x to the 0.05,
等于 x 的0.05次方

150
00:04:59,620 --> 00:05:01,380
and now my new
现在我的新特征变量

151
00:05:01,610 --> 00:05:03,050
feature x Mu looks more
xNew 比原来的特征变量

152
00:05:03,250 --> 00:05:04,490
Gaussian than my previous one
看起来更具像高斯分布

153
00:05:04,510 --> 00:05:05,560
and then I might instead use
因此我就可以用这个新的

154
00:05:05,850 --> 00:05:07,070
this new feature to feed
特征变量来输入到我的

155
00:05:07,380 --> 00:05:09,390
into my anomaly detection algorithm.
异常检测算法中

156
00:05:10,150 --> 00:05:12,100
And of course, there is more than one way to do this.
当然 实现这一功能的方法不唯一

157
00:05:12,410 --> 00:05:14,530
You could also have hist of log of
你也可以用 hist(log(x), 50)

158
00:05:14,710 --> 00:05:17,320
x, that's another example of a transformation you can use.
这是另一种你可以选择的转换方法

159
00:05:18,270 --> 00:05:20,410
And, you know, that also look pretty Gaussian.
这同样会让你的数据看起来更像高斯分布

160
00:05:20,870 --> 00:05:22,040
So, I can also define x
所以 我们也可以

161
00:05:22,230 --> 00:05:23,760
mu equals log of x.
让 xNew 等于 log(x)

162
00:05:24,220 --> 00:05:25,120
and that would be another
这是另一种可以选用的

163
00:05:25,300 --> 00:05:26,890
pretty good choice of a feature to use.
很好的特征变量

164
00:05:28,040 --> 00:05:29,400
So to summarize, if you
我们来总结一下

165
00:05:29,520 --> 00:05:30,580
plot a histogram with the data,
如果你画出数据的直方图

166
00:05:31,000 --> 00:05:31,690
and find that it looks pretty
并且发现图形看起来

167
00:05:31,940 --> 00:05:33,460
non-Gaussian, it's worth playing
非常不像正态分布

168
00:05:33,740 --> 00:05:35,110
around a little bit with
那么应该进行一些

169
00:05:35,280 --> 00:05:37,120
different transformations like these, to
不同的转换 就像这些

170
00:05:37,290 --> 00:05:38,190
see if you can make
通过这些方法

171
00:05:38,300 --> 00:05:39,410
your data look a little bit more
来让你的数据看起来

172
00:05:39,570 --> 00:05:40,520
Gaussian, before you feed it to
更具有高斯分布的特点

173
00:05:40,770 --> 00:05:41,970
your learning algorithm, although even if
然后你再把数据输入到学习算法

174
00:05:42,050 --> 00:05:43,550
you don't, it might work okay.
虽然说 你不这么做也可以

175
00:05:43,850 --> 00:05:45,070
But I usually do take this step.
但我通常还是会进行这一步

176
00:05:45,850 --> 00:05:46,880
Now, the second thing I want
下面我想讲第二个问题

177
00:05:46,970 --> 00:05:48,280
to talk about is, how do
那就是你如何得到

178
00:05:48,400 --> 00:05:51,540
you come up with features for an anomaly detection algorithm.
异常检测算法的特征变量

179
00:05:52,650 --> 00:05:53,780
And the way I often do
我通常用的办法是

180
00:05:53,990 --> 00:05:56,490
so, is via an error analysis procedure.
通过一个误差分析步骤

181
00:05:57,630 --> 00:05:58,590
So what I mean by that,
我的意思是

182
00:05:58,970 --> 00:05:59,960
is that this is really similar
这跟我们之前

183
00:06:00,320 --> 00:06:02,320
to the error analysis procedure that
学习监督学习算法时的

184
00:06:02,450 --> 00:06:04,600
we have for supervised learning, where
误差分析步骤是类似的

185
00:06:04,860 --> 00:06:06,810
we would train a
也就是说 我们先完整地训练出

186
00:06:06,860 --> 00:06:08,220
complete algorithm, and run the
一个学习算法

187
00:06:08,350 --> 00:06:09,980
algorithm on a cross validation set,
然后在一组交叉验证集上运行算法

188
00:06:10,840 --> 00:06:11,870
and look at the examples it gets
然后找出那些预测出错的样本

189
00:06:12,230 --> 00:06:13,500
wrong, and see if
然后再看看

190
00:06:13,580 --> 00:06:14,800
we can come up with extra features
我们能否找到一些其他的特征变量

191
00:06:15,370 --> 00:06:16,440
to help the algorithm do
来帮助学习算法

192
00:06:16,580 --> 00:06:17,870
better on the examples
让它在那些交叉验证时

193
00:06:18,280 --> 00:06:19,850
that it got wrong in the cross-validation set.
判断出错的样本中表现更好

194
00:06:21,060 --> 00:06:23,380
So lets try
让我们来用一个例子

195
00:06:24,040 --> 00:06:25,960
to reason through an example of this process.
详细解释一下刚才说的这一过程

196
00:06:26,950 --> 00:06:28,680
In anomaly detection, we are
在异常检测中

197
00:06:28,880 --> 00:06:29,690
hoping that p of x will
我们希望 p(x) 的值

198
00:06:29,840 --> 00:06:30,910
be large for the normal examples
对正常样本来说是比较大的

199
00:06:31,760 --> 00:06:33,180
and it will be small for the anomalous examples.
而对异常样本来说 值是很小的

200
00:06:34,400 --> 00:06:35,370
And so a pretty common problem
因此 一个很常见的问题是

201
00:06:35,950 --> 00:06:37,780
would be if p of x is comparable,
p(x) 是具有可比性的

202
00:06:38,480 --> 00:06:41,540
maybe both are large for both the normal and the anomalous examples.
也许正常样本和异常样本的值都很大

203
00:06:42,940 --> 00:06:44,380
Lets look at a specific example of that.
我们来看一个具体点的例子

204
00:06:45,150 --> 00:06:46,760
Let's say that this is my unlabeled data.
假如说这是我的无标签数据

205
00:06:47,120 --> 00:06:47,970
So, here I have just one
那么 我只有一个特征变量 x1

206
00:06:48,210 --> 00:06:51,130
feature, x1 and so I'm gonna fit a Gaussian to this.
我要用一个高斯分布来拟合它

207
00:06:52,160 --> 00:06:55,990
And maybe my Gaussian that I fit to my data looks like that.
假如我的数据拟合出的高斯分布是这样的

208
00:06:57,300 --> 00:06:59,130
And now let's say I have an anomalous example,
现在假如我有一个异常样本

209
00:06:59,670 --> 00:07:00,480
and let's say that my anomalous example
假如我的异常样本中

210
00:07:01,080 --> 00:07:02,850
takes on an x value of 2.5.
x 的取值为2.5

211
00:07:03,020 --> 00:07:06,420
So I plot my anomalous example there.
因此 我画出我的异常样本

212
00:07:07,200 --> 00:07:08,120
And you know, it's kind of buried
你不难发现

213
00:07:08,650 --> 00:07:09,730
in the middle of a bunch
它看起来就像被淹没在

214
00:07:09,880 --> 00:07:11,690
of normal examples, and so,
一堆正常样本中似的

215
00:07:13,450 --> 00:07:14,850
just this anomalous example
我用绿色画出来的

216
00:07:15,460 --> 00:07:16,780
that I've drawn in green, it gets a
这个异常样本

217
00:07:16,820 --> 00:07:18,550
pretty high probability, where it's the
它的概率值很大

218
00:07:18,730 --> 00:07:20,000
height of the blue curve,
是蓝色曲线的高度

219
00:07:20,960 --> 00:07:22,280
and the algorithm fails to
而我们的算法

220
00:07:22,390 --> 00:07:23,840
flag this as an anomalous example.
没能把这个样本判断为异常

221
00:07:25,320 --> 00:07:26,600
Now, if this were maybe aircraft
现在如果说这代表

222
00:07:27,000 --> 00:07:29,540
engine manufacturing or something, what
飞机引擎的制造或者别的什么

223
00:07:29,680 --> 00:07:30,490
I would do is, I would actually
那么我会做的是

224
00:07:30,860 --> 00:07:32,370
look at my training examples and
我会看看我的训练样本

225
00:07:32,840 --> 00:07:34,500
look at what went wrong with
然后看看到底是

226
00:07:34,730 --> 00:07:36,920
that particular aircraft engine, and
哪一个具体的飞机引擎出错了

227
00:07:37,030 --> 00:07:38,360
see, if looking at that
看看通过这个样本

228
00:07:38,720 --> 00:07:40,720
example can inspire me to
能不能启发我

229
00:07:40,860 --> 00:07:41,800
come up with a new feature
想出一个新的特征 x2

230
00:07:42,290 --> 00:07:43,890
x2, that helps to distinguish
来帮助算法区别出

231
00:07:44,650 --> 00:07:46,530
between this bad example, compared
不好的样本

232
00:07:46,900 --> 00:07:47,850
to the rest of my
和我剩下的正确的样本

233
00:07:48,530 --> 00:07:49,850
red examples, compared to all
也就是那些红色的叉叉

234
00:07:50,980 --> 00:07:51,600
of my normal aircraft engines.
或者说正常的飞机引擎样本

235
00:07:52,790 --> 00:07:53,840
And if I managed to do
如果我这样做的话

236
00:07:54,000 --> 00:07:54,910
so, the hope would be then,
我们的期望是

237
00:07:55,150 --> 00:07:56,540
that, if I can create a
创建一个新的特征

238
00:07:56,610 --> 00:07:59,360
new feature, X2, so that
x2 使得

239
00:07:59,610 --> 00:08:01,490
when I re-plot my data, if
当我重新画数据时

240
00:08:01,580 --> 00:08:02,530
I take all my normal examples
如果我用训练集中的

241
00:08:02,770 --> 00:08:04,420
of my training set, hopefully
所有正常样本

242
00:08:04,750 --> 00:08:05,560
I find that all my training
我应该就会发现

243
00:08:05,710 --> 00:08:07,380
examples are these red crosses here.
所有的训练样本都是这里的红叉了

244
00:08:08,210 --> 00:08:09,580
And hopefully, if I find
我们也希望能看到

245
00:08:09,860 --> 00:08:11,390
that for my anomalous example, the
对于异常样本

246
00:08:11,480 --> 00:08:13,490
feature x2 takes on the the unusual value.
这个新特征变量 x2 的值会看起来是异常的

247
00:08:14,470 --> 00:08:15,820
So for my green example
因此对于我这里的绿色的样本

248
00:08:16,290 --> 00:08:18,670
here, this anomaly, right, my
这是异常的样本 对吧

249
00:08:18,940 --> 00:08:20,800
X1 value, is still 2.5.
我的 x1 值仍然是2.5

250
00:08:21,260 --> 00:08:22,900
Then maybe my X2 value, hopefully
那么我的 x2 很有可能

251
00:08:23,290 --> 00:08:24,530
it takes on a very large
是一个比较大的值

252
00:08:24,840 --> 00:08:26,710
value like 3.5 over there,
比如这里的3.5

253
00:08:27,940 --> 00:08:28,450
or a very small value.
或者一个非常小的值

254
00:08:29,450 --> 00:08:30,530
But now, if I model
现在如果我再来给数据建模

255
00:08:30,970 --> 00:08:32,480
my data, I'll find that
我会发现

256
00:08:33,050 --> 00:08:34,660
my anomaly detection algorithm gives
我的异常检测算法

257
00:08:35,240 --> 00:08:36,830
high probability to data
会在中间区域

258
00:08:37,190 --> 00:08:39,160
in the central regions, slightly lower
给出一个较高的概率

259
00:08:39,200 --> 00:08:42,470
probability to that, sightly lower probability to that.
然后越到外层越小

260
00:08:42,660 --> 00:08:43,960
An example that's all the
到了那个绿色的样本

261
00:08:44,070 --> 00:08:45,450
way out there, my algorithm will
我的异常检测算法

262
00:08:45,630 --> 00:08:46,720
now give very low probability
会给出非常小的概率值

263
00:08:48,360 --> 00:08:48,360
会给出非常小的概率值

264
00:08:48,360 --> 00:08:48,360
to.

265
00:08:48,510 --> 00:08:49,170
And so, the process of this
所以这个过程

266
00:08:49,230 --> 00:08:50,320
is, really look at the
实际上就是

267
00:08:51,430 --> 00:08:52,570
mistakes that it is making.
看看哪里出了错

268
00:08:52,830 --> 00:08:54,370
Look at the anomaly that the algorithm
看看那些

269
00:08:54,580 --> 00:08:56,020
is failing to flag, and see
算法没能正确标记的异常点

270
00:08:56,320 --> 00:08:59,100
if that inspires you to create some new feature.
看看你能不能得到启发来创造新的特征变量

271
00:08:59,590 --> 00:09:01,180
So find something unusual about
所以也就是说

272
00:09:01,470 --> 00:09:02,590
that aircraft engine and use
找一找飞机引擎中的不寻常的问题

273
00:09:02,800 --> 00:09:03,640
that to create a new feature,
然后来建立一些新特征变量

274
00:09:04,530 --> 00:09:05,780
so that with this new
有了这些新的特征变量

275
00:09:05,900 --> 00:09:07,140
feature it becomes easier to
应该就能更容易

276
00:09:07,400 --> 00:09:09,250
distinguish the anomalies from your good examples.
从正常样本中区别出异常来

277
00:09:09,880 --> 00:09:11,170
And so that's the
这就是误差分析的过程

278
00:09:11,280 --> 00:09:12,600
process of error analysis
这就是误差分析的过程

279
00:09:14,020 --> 00:09:15,360
and using that to create
以及如何为异常检查算法

280
00:09:15,750 --> 00:09:17,100
new features for anomaly detection.
建立新的特征变量

281
00:09:17,770 --> 00:09:18,980
Finally, let me share with
最后 我想与你分享一些

282
00:09:19,090 --> 00:09:20,440
you my thinking on how I
我平时在为异常检查算法

283
00:09:20,630 --> 00:09:23,190
usually go about choosing features for anomaly detection.
选择特征变量时的一些思考

284
00:09:24,350 --> 00:09:27,700
So, usually, the way I think about choosing features is
通常来说 我想到的选择特征变量的方法是

285
00:09:27,960 --> 00:09:29,160
I want to choose features that will
我会选那些取值

286
00:09:29,270 --> 00:09:30,610
take on either very, very
既不会特别特别大

287
00:09:30,860 --> 00:09:32,000
large values, or very, very
也不会特别特别小的

288
00:09:32,110 --> 00:09:33,890
small values, for examples
那些特征变量

289
00:09:34,750 --> 00:09:36,420
that I think might turn out to be anomalies.
比如说

290
00:09:37,850 --> 00:09:38,710
So let's use our example
我们还是用这个数据中心中

291
00:09:39,060 --> 00:09:41,820
again of monitoring the computers in a data center.
监控计算机的例子

292
00:09:42,250 --> 00:09:43,560
And so you have lots of
比如 在一个数据中心

293
00:09:43,630 --> 00:09:44,930
machines, maybe thousands, or tens
你有很多台电脑

294
00:09:45,170 --> 00:09:47,830
of thousands of machines in a data center.
也许上千 或者上万台

295
00:09:48,310 --> 00:09:49,410
And we want to know if one
我们想要知道的是

296
00:09:49,580 --> 00:09:50,640
of the machines, one of our
是不是有哪一台机器

297
00:09:50,710 --> 00:09:53,320
computers is acting up, so doing something strange.
运作不正常了

298
00:09:54,180 --> 00:09:56,050
So here are examples of features you may choose,
这里给出了几种可选的特征变量

299
00:09:57,020 --> 00:09:59,630
maybe memory used, number of disc accesses, CPU load, network traffic.
包括占用内存 磁盘每秒访问次数 CPU负载 网络流量

300
00:10:01,040 --> 00:10:01,960
But now, lets say that I
现在假如说

301
00:10:02,220 --> 00:10:03,040
suspect one of the failure
我怀疑某个出错的情况

302
00:10:03,470 --> 00:10:04,580
cases, let's say that
假如说 我认为

303
00:10:05,230 --> 00:10:06,970
in my data set I think
在我的数据中

304
00:10:07,150 --> 00:10:08,460
that CPU load the network traffic
我的CPU负载和网络流量

305
00:10:08,990 --> 00:10:10,820
tend to grow linearly with each other.
应该互为线性关系

306
00:10:11,110 --> 00:10:12,120
Maybe I'm running a bunch of
可能我运行了一组

307
00:10:12,220 --> 00:10:13,370
web servers, and so, here
网络服务器

308
00:10:13,750 --> 00:10:15,050
if one of my servers is
如果其中一个服务器

309
00:10:15,310 --> 00:10:16,530
serving a lot of users,
在对许多用户服务

310
00:10:16,850 --> 00:10:19,050
I have a very high CPU load, and have a very high network traffic.
那么我的CPU负载和网络流量都很大

311
00:10:20,230 --> 00:10:21,360
But let's say, I think,
现在假如说

312
00:10:21,840 --> 00:10:23,280
let's say I have a suspicion, that
我怀疑其中一个出错的情形

313
00:10:23,390 --> 00:10:24,890
one of the failure cases is
是我的计算机在执行一个任务时

314
00:10:25,180 --> 00:10:26,240
if one of my computers
进入了一个死循环

315
00:10:26,530 --> 00:10:29,590
has a job that gets stuck in some infinite loop.
因此被卡住了

316
00:10:29,670 --> 00:10:30,750
So if I think one of
意思就是说

317
00:10:30,800 --> 00:10:32,240
the failure cases, is one of
假如我感觉

318
00:10:32,420 --> 00:10:33,470
my machines, one of my
我的其中一台机器

319
00:10:34,380 --> 00:10:36,020
web servers--server code--
或者说其中一台服务器的代码

320
00:10:36,680 --> 00:10:37,990
gets stuck in some infinite loop,
执行到一个死循环卡住了

321
00:10:38,230 --> 00:10:39,550
and so the CPU load grows,
因此CPU负载升高

322
00:10:40,380 --> 00:10:41,490
but the network traffic doesn't because
但网络流量没有升高

323
00:10:41,560 --> 00:10:42,790
it's just spinning it's
因为只是CPU执行了

324
00:10:42,940 --> 00:10:44,570
wheels and doing a lot of CPU work, you know,
较多的工作 所以负载较大

325
00:10:44,870 --> 00:10:46,000
stuck in some infinite loop.
卡在了死循环里

326
00:10:46,930 --> 00:10:47,850
In that case, to detect
在这种情况下

327
00:10:48,240 --> 00:10:49,610
that type of anomaly, I might
要检测出异常

328
00:10:49,780 --> 00:10:52,440
create a new feature, X5,
我可以新建一个特征 x5

329
00:10:53,170 --> 00:10:55,130
which might be CPU load
x5 等于 CPU负载

330
00:10:56,600 --> 00:11:00,120
divided by network traffic.
除以网络流量

331
00:11:01,230 --> 00:11:02,810
And so here X5 will take
因此 x5 的值

332
00:11:03,180 --> 00:11:04,860
on a unusually large value
将会变得不寻常地大

333
00:11:05,700 --> 00:11:06,410
if one of the machines has a
如果某一台机器

334
00:11:06,790 --> 00:11:08,190
very large CPU load but
具有较大的CPU负载

335
00:11:08,470 --> 00:11:09,980
not that much network traffic and
但网络流量正常的话

336
00:11:10,250 --> 00:11:11,030
so this will be a
因此 这将成为一个

337
00:11:11,160 --> 00:11:12,390
feature that will help your
很好的特征 能帮助你

338
00:11:12,490 --> 00:11:14,180
anomaly detection capture, a certain type of anomaly.
检测出某种类型的异常情况

339
00:11:15,000 --> 00:11:16,700
And you can
当然 你还可以

340
00:11:16,840 --> 00:11:19,060
also get creative and come up with other features as well.
用同样的方法得到更多其他的特征

341
00:11:19,230 --> 00:11:20,090
Like maybe I have a feature
比如说我可以

342
00:11:20,570 --> 00:11:22,050
x6 thats CPU load
建立一个特征 x6

343
00:11:22,880 --> 00:11:25,540
squared divided by network traffic.
等于 CPU负载的平方除以网络流量

344
00:11:27,030 --> 00:11:28,280
And this would be another variant
这就像是特征 x5 的一个变体

345
00:11:28,950 --> 00:11:29,910
of a feature like x5 to try
实际上它捕捉的异常

346
00:11:30,020 --> 00:11:32,120
to capture anomalies where one
仍然是你的机器

347
00:11:32,280 --> 00:11:33,650
of your machines has a very
是否具有一个比较高的

348
00:11:33,800 --> 00:11:35,030
high CPU load, that maybe
CPU 负载 但没有一个

349
00:11:35,290 --> 00:11:37,100
doesn't have a commensurately large network traffic.
同样很大的网络流量

350
00:11:38,540 --> 00:11:40,080
And by creating features like
通过这样的方法

351
00:11:40,290 --> 00:11:41,560
these, you can start to capture
建立新的特征变量

352
00:11:42,770 --> 00:11:44,550
anomalies that correspond to
你就可以通过不同特征变量的组合

353
00:11:45,690 --> 00:11:48,270
unusual combinations of values of the features.
捕捉到对应的不寻常现象

354
00:11:50,990 --> 00:11:52,090
So in this video we
在这段视频中

355
00:11:52,260 --> 00:11:53,550
talked about how to and
我们介绍了如何选择特征

356
00:11:53,690 --> 00:11:54,670
take a feature, and maybe transform
以及对特征进行一些

357
00:11:55,120 --> 00:11:56,680
it a little bit, so that
小小的转换

358
00:11:56,830 --> 00:11:57,910
it becomes a bit more Gaussian,
让数据更像正态分布

359
00:11:58,260 --> 00:12:00,480
before feeding into an anomaly detection algorithm.
然后再把数据输入异常检测算法

360
00:12:00,950 --> 00:12:02,110
And also the error analysis
同时也介绍了建立特征时

361
00:12:02,740 --> 00:12:04,220
in this process of creating features
进行的误差分析方法

362
00:12:04,870 --> 00:12:06,710
to try to capture different types of anomalies.
来捕捉各种异常的可能

363
00:12:07,550 --> 00:12:10,300
And with these sorts of guidelines hopefully that will help you
希望你通过这些方法

364
00:12:10,850 --> 00:12:12,180
to choose good features, to give to
能够了解如何选择好的特征变量

365
00:12:12,460 --> 00:12:14,310
your anomaly detection algorithm, to
从而帮助你的异常检测算法

366
00:12:14,430 --> 00:12:15,920
help it capture all sorts of anomalies.
捕捉到各种不同的异常情况 【教育无边界字幕组】翻译：所罗门捷列夫 校对：竹二个 审核：小白_远游

