1
00:00:00,330 --> 00:00:01,420
In the last video we talked
在我们谈到的上一个视频（字幕翻译：中国海洋大学 黄海广 haiguang2000@qq.com）

2
00:00:01,750 --> 00:00:03,510
about the Multivariate Gaussian Distribution
关于多元高斯分布

3
00:00:04,720 --> 00:00:06,990
and saw some examples of the
，看到的一些

4
00:00:07,230 --> 00:00:08,830
sorts of distributions you can model, as
建立的各种分布模型，

5
00:00:08,960 --> 00:00:10,880
you vary the parameters, mu and sigma.
当你改变参数，mu和sigma。

6
00:00:11,830 --> 00:00:13,190
In this video, let's take those
在这段视频中，让我们这些

7
00:00:13,420 --> 00:00:14,690
ideas, and apply them
想法，并应用它们

8
00:00:14,890 --> 00:00:17,550
to develop a different anomaly detection algorithm.
制定一个不同的异常检测算法。

9
00:00:19,880 --> 00:00:21,890
To recap the multivariate Gaussian
要回顾一下多元高斯

10
00:00:22,270 --> 00:00:23,080
distribution and the multivariate normal
分布和多元正态分布

11
00:00:23,770 --> 00:00:26,640
distribution has two parameters, mu and sigma.
分布有两个参数，mu和sigma。

12
00:00:27,210 --> 00:00:28,850
Where mu this an n
其中mu这一个n

13
00:00:28,990 --> 00:00:31,110
dimensional vector and sigma,
维向量和sigma，

14
00:00:32,110 --> 00:00:34,430
the covariance matrix, is an
的协方差矩阵，是一种

15
00:00:34,810 --> 00:00:36,110
n by n matrix.
n乘n的矩阵。

16
00:00:37,330 --> 00:00:38,710
And here's the formula for
而这里的公式

17
00:00:38,740 --> 00:00:39,780
the probability of X, as
X的概率，如

18
00:00:40,480 --> 00:00:41,870
parameterized by mu and
按mu和参数化

19
00:00:42,240 --> 00:00:43,770
sigma, and as you
sigma，和你的

20
00:00:43,890 --> 00:00:45,010
vary mu and sigma, you
变量mu和sigma，你

21
00:00:45,100 --> 00:00:45,830
can get a range of different
可以得到一个范围的不同

22
00:00:46,240 --> 00:00:47,700
distributions, like, you know,
分布一样，你知道的，

23
00:00:47,760 --> 00:00:48,990
these are three examples of the
这些都是三个样本

24
00:00:49,060 --> 00:00:50,660
ones that we saw in the previous video.
那些我们在以前的视频看了。

25
00:00:51,800 --> 00:00:53,100
So let's talk about the
因此，让我们谈谈

26
00:00:53,260 --> 00:00:54,600
parameter fitting or the
参数拟合或

27
00:00:54,670 --> 00:00:56,260
parameter estimation problem. The
参数估计问题。该

28
00:00:56,800 --> 00:00:58,480
question, as usual, is if
问题，像往常一样，如果是

29
00:00:58,610 --> 00:00:59,890
I have a set of examples
我有一组样本

30
00:01:00,500 --> 00:01:02,140
X1 through XM and here each
X1到XM并且这里的每个

31
00:01:02,410 --> 00:01:03,750
of these examples is an
这些样本是一个

32
00:01:04,420 --> 00:01:05,820
n dimensional vector and I think my
n维向量，我想我的

33
00:01:06,000 --> 00:01:08,280
examples come from a multivariate Gaussian distribution.
样本来自一个多元高斯分布。

34
00:01:09,470 --> 00:01:12,450
How do I try to estimate my parameters mu and sigma?
我如何尝试估计我的参数mu和sigma？

35
00:01:13,440 --> 00:01:15,070
Well the standard formulas for
以及标准公式的

36
00:01:15,270 --> 00:01:17,170
estimating them is you
估计是：你

37
00:01:17,330 --> 00:01:18,270
set mu to be just
设置mu是

38
00:01:18,580 --> 00:01:19,960
the average of your training examples.
你的训练样本的平均值。

39
00:01:21,010 --> 00:01:22,770
And you set sigma to be equal to this.
并设置sigma等于这一点。

40
00:01:23,130 --> 00:01:24,120
And this is actually just
这其实只是

41
00:01:24,250 --> 00:01:25,200
like the sigma that we had
像我们有sigma

42
00:01:25,490 --> 00:01:26,860
written out, when we were
写出来，当我们

43
00:01:27,150 --> 00:01:28,740
using the PCA or
使用PCA即

44
00:01:28,850 --> 00:01:30,750
the Principal Components Analysis algorithm.
主成分分析算法。

45
00:01:31,820 --> 00:01:32,730
So you just plug in these
所以你只需插入这

46
00:01:32,850 --> 00:01:34,290
two formulas and this
两个公式，这

47
00:01:34,570 --> 00:01:36,720
would give you your estimated parameter
会给你你估计的参数

48
00:01:37,160 --> 00:01:39,440
mu and your estimated parameter sigma.
mu和你估计的参数sigma。

49
00:01:41,580 --> 00:01:43,860
So given the data set here is how you estimate mu and sigma.
所以，这里给出的数据集是你如何估计mu和sigma。

50
00:01:44,270 --> 00:01:45,350
Let's take this method
让我们以这种方法

51
00:01:46,020 --> 00:01:47,410
and just plug it
而只需将其插入

52
00:01:47,610 --> 00:01:49,130
into an anomaly detection algorithm.
到异常检测算法。

53
00:01:50,050 --> 00:01:51,020
So how do we
那么，我们如何

54
00:01:51,080 --> 00:01:52,200
put all of this together to
把所有这一切共同

55
00:01:52,420 --> 00:01:54,160
develop an anomaly detection algorithm?
开发一个异常检测算法？

56
00:01:54,640 --> 00:01:55,780
Here 's what we do.
下面是我们做什么。

57
00:01:56,580 --> 00:01:57,480
First we take our training
首先，我们把我们的训练

58
00:01:57,960 --> 00:01:59,110
set, and we fit the
集，和我们的拟合

59
00:01:59,170 --> 00:02:00,210
model, we fit P
模型，我们计算P

60
00:02:00,390 --> 00:02:01,640
of X, by, you know, setting
的X，要知道，设定

61
00:02:02,100 --> 00:02:02,720
mu and sigma as described
mu和描述的一样sigma

62
00:02:03,780 --> 00:02:05,410
on the previous slide.
在上一张幻灯片。

63
00:02:07,370 --> 00:02:08,510
Next when you are given
您将得到下一个

64
00:02:08,720 --> 00:02:10,170
a new example X. So
一个新的样本X，所以

65
00:02:10,510 --> 00:02:11,430
if you are given a test example,
如果给你一个测试的样本，

66
00:02:12,450 --> 00:02:15,240
lets take an earlier example to have a new example out here.
让作为一个早期的样本有一个新的样本在这里。

67
00:02:15,880 --> 00:02:16,790
And that is my test example.
那是我的测试样本。

68
00:02:18,220 --> 00:02:19,670
Given the new example X, what
鉴于新的样本X，

69
00:02:19,810 --> 00:02:21,220
we are going to do is compute
我们要做的是计算

70
00:02:21,770 --> 00:02:23,420
P of X, using this
p(x)，用这

71
00:02:23,690 --> 00:02:26,250
formula for the multivariate Gaussian distribution.
式为多元高斯分布。

72
00:02:27,720 --> 00:02:29,220
And then, if P of
然后，如果p(x)

73
00:02:29,470 --> 00:02:30,840
X is very small, then we
是非常小的，那么我们

74
00:02:30,950 --> 00:02:31,800
flagged it as an anomaly,
把它当作一个异常，

75
00:02:32,440 --> 00:02:33,570
whereas, if P of X is greater
然而，如果p(x)是远大于

76
00:02:33,750 --> 00:02:35,520
than that parameter epsilon, then
参数epsilon，则

77
00:02:35,670 --> 00:02:39,190
we don't flag it as an anomaly.
我们不会将其标记为异常。

78
00:02:39,400 --> 00:02:42,240
So it turns out, if we were to fit a multivariate Gaussian distribution to this data set,
所以，事实证明，如果我们要拟合多元高斯分布到这组数据，

79
00:02:42,560 --> 00:02:44,220
so just the red crosses, not the green example,
所以只是图中的红叉，不是绿的样本，

80
00:02:45,190 --> 00:02:46,100
you end up with a Gaussian
你完成了一个高斯

81
00:02:46,300 --> 00:02:48,080
distribution that places lots
分布的地方很多

82
00:02:48,350 --> 00:02:49,690
of probability in the central
在中央的概率

83
00:02:49,910 --> 00:02:51,840
region, slightly less probability here,
区域，这里概率稍微小，

84
00:02:52,440 --> 00:02:53,360
slightly less probability here,
在这里概率略少，

85
00:02:54,110 --> 00:02:55,010
slightly less probability here,
在这里概率略少，

86
00:02:56,020 --> 00:02:59,280
and very low probability at the point that is way out here.
并在该点是在这里的概率非常低。

87
00:03:01,260 --> 00:03:02,350
And so, if you apply
所以，如果你应用

88
00:03:02,840 --> 00:03:04,730
the multivariate Gaussian distribution to
多元高斯分布

89
00:03:04,920 --> 00:03:06,530
this example, it will actually
本例中，将实际

90
00:03:06,930 --> 00:03:08,610
correctly flag that example.
正确地标记样本。

91
00:03:09,520 --> 00:03:09,920
as an anomaly.
作为一个异常。

92
00:03:16,860 --> 00:03:18,080
Finally it's worth saying
最后，值得一说

93
00:03:18,430 --> 00:03:19,640
a few words about what is
简要描述

94
00:03:19,760 --> 00:03:21,900
the relationship between the
他们之间的关系：

95
00:03:21,950 --> 00:03:23,810
multivariate Gaussian distribution model, and
多元高斯分布模型和

96
00:03:24,030 --> 00:03:25,440
the original model, where we
原始模型，在那里我们

97
00:03:25,500 --> 00:03:26,870
were modeling P(x)
被建模的P

98
00:03:26,940 --> 00:03:28,000
X as a product of this
作为该商品

99
00:03:28,110 --> 00:03:28,890
P of X1, P of X2,
P(X1)，P(X2)，

100
00:03:29,150 --> 00:03:31,420
up to P of Xn.
到P(Xn)。

101
00:03:32,750 --> 00:03:33,890
It turns out that you can
事实证明，你可以

102
00:03:34,090 --> 00:03:35,310
prove mathematically, I'm not
数学上证明，我不是

103
00:03:35,590 --> 00:03:36,470
going to do the proof here, but
要在这里做了证明，但

104
00:03:36,540 --> 00:03:38,120
you can prove mathematically that this
你能证明在数学上，这

105
00:03:38,300 --> 00:03:40,610
relationship, between the
关系，之间的

106
00:03:40,650 --> 00:03:42,240
multivariate Gaussian model and
多元高斯模型和

107
00:03:42,400 --> 00:03:44,030
this original one. And in
这种原始模型。而且

108
00:03:44,110 --> 00:03:45,420
particular, it turns out
特别是，它原来

109
00:03:45,660 --> 00:03:47,500
that the original model corresponds
原模型对应

110
00:03:48,440 --> 00:03:50,330
to multivariate Gaussians, where
以多变量高斯，其中

111
00:03:50,660 --> 00:03:51,980
the contours of the
的轮廓

112
00:03:52,040 --> 00:03:54,060
Gaussian are always axis aligned.
高斯总是轴线对齐。

113
00:03:55,410 --> 00:03:57,350
So all three of
因此，所有三个

114
00:03:57,470 --> 00:03:59,390
these are examples of
这些样本

115
00:03:59,510 --> 00:04:01,300
Gaussian distributions that you
高斯分布，你

116
00:04:01,480 --> 00:04:02,930
can fit using the original model.
可以适合使用原始模型。

117
00:04:03,190 --> 00:04:04,090
It turns out that that corresponds
原来，对应

118
00:04:05,040 --> 00:04:06,920
to multivariate Gaussian, where, you
以多元高斯，在那里，你

119
00:04:07,300 --> 00:04:09,830
know, the ellipsis here, the contours
知道，这里的省略号，轮廓

120
00:04:10,730 --> 00:04:13,600
of this distribution--it
这种分布的 - 它

121
00:04:13,800 --> 00:04:15,190
turns out that this model actually
事实证明，这种模式实际上

122
00:04:15,470 --> 00:04:17,030
corresponds to a special
对应于一个特殊的

123
00:04:17,490 --> 00:04:19,160
case of a multivariate Gaussian distribution.
情况下的多元高斯分布。

124
00:04:19,740 --> 00:04:21,110
And in particular, this special
特别是，这个特殊的

125
00:04:21,410 --> 00:04:22,930
case is defined by constraining
例子通过约束定义

126
00:04:24,460 --> 00:04:25,710
the distribution of p
p(x)分布

127
00:04:25,880 --> 00:04:27,110
of x, the multivariate a Gaussian
，多元高斯

128
00:04:27,270 --> 00:04:28,070
distribution of p of x,
分布的p(x)，

129
00:04:28,980 --> 00:04:30,740
so that the contours of
这个

130
00:04:30,920 --> 00:04:32,340
the probability density function, of
概率密度函数的轮廓，

131
00:04:32,440 --> 00:04:35,010
the probability distribution function, are axis aligned.
这个概率分布函数，是轴对齐。

132
00:04:35,700 --> 00:04:37,400
And so you can get a p
所以你可以得到p(x)

133
00:04:37,940 --> 00:04:39,550
of x with a
是一个

134
00:04:39,860 --> 00:04:41,430
multivariate Gaussian that looks like
多元高斯分布，看起来像

135
00:04:41,630 --> 00:04:43,850
this, or like this, or like this.
这样，或者这样，或者像这样。

136
00:04:44,050 --> 00:04:44,990
And you notice, that in all
而且你注意到，在所有

137
00:04:45,210 --> 00:04:47,820
3 of these examples, these ellipses,
第三个样本中，这些椭圆

138
00:04:48,740 --> 00:04:50,490
or these ovals that I'm drawing, have
或者，这些椭圆形的我画，有

139
00:04:50,690 --> 00:04:53,190
their axes aligned with the X1 X2 axes.
其轴线对准X1 X2轴。

140
00:04:54,260 --> 00:04:55,920
And what we do not have, is
而我们没有，是

141
00:04:56,200 --> 00:04:57,310
a set of contours
一组轮廓

142
00:04:58,050 --> 00:05:00,450
that are at an angle, right?
这是一个角度，对不对？

143
00:05:00,790 --> 00:05:02,620
And this corresponded to examples where
与此相对应的样本在那里

144
00:05:02,790 --> 00:05:06,780
sigma is equal to 1 1, 0.8, 0.8.
sigma等于1 1，0.8，0.8。

145
00:05:06,840 --> 00:05:08,790
Let's say, with non-0 elements on the
比方说，对非0元素

146
00:05:09,070 --> 00:05:10,780
off diagonals.
关闭对角线。

147
00:05:11,180 --> 00:05:11,970
So, it turns out that
所以，事实证明，

148
00:05:12,380 --> 00:05:13,980
it's possible to show mathematically that
它是可能的数学证明

149
00:05:14,260 --> 00:05:16,400
this model actually is the
这种模式实际上是

150
00:05:16,480 --> 00:05:18,300
same as a multivariate Gaussian
同样作为多元高斯

151
00:05:18,750 --> 00:05:20,570
distribution but with a constraint.
分布但有限制。

152
00:05:21,250 --> 00:05:24,400
And the constraint is that the
约束是

153
00:05:24,480 --> 00:05:26,710
covariance matrix sigma must
协方差矩阵sigma必须

154
00:05:27,240 --> 00:05:28,900
have 0's on the off diagonal elements.
有0的对非对角元素。

155
00:05:29,360 --> 00:05:30,830
In particular, the covariance matrix sigma,
特别地，协方差矩阵Σ和

156
00:05:31,240 --> 00:05:32,450
this thing here, it would
这个东西在这里，它会

157
00:05:32,550 --> 00:05:33,940
be sigma squared 1, sigma
被sigma平方1，sigma

158
00:05:34,190 --> 00:05:36,050
squared 2, down to sigma
平方2，下至sigma

159
00:05:36,350 --> 00:05:38,660
squared n, and then
平方N，然后

160
00:05:39,530 --> 00:05:40,550
everything on the off diagonal
一切都在对角线关闭

161
00:05:41,020 --> 00:05:42,210
entries, all of these elements
条目，所有这些元素

162
00:05:43,640 --> 00:05:45,110
above and below the diagonal of the matrix,
上面和下面的对角矩阵，

163
00:05:45,640 --> 00:05:46,850
all of those are going to be zero.
所有这些都将是零。

164
00:05:47,900 --> 00:05:49,380
And in fact if you take
而事实上，如果你拿

165
00:05:49,680 --> 00:05:50,980
these values of sigma, sigma
那些sigma的值，sigma

166
00:05:51,330 --> 00:05:52,280
squared 1, sigma squared 2,
平方1，sigma平方2，

167
00:05:52,320 --> 00:05:53,380
down to sigma squared n,
下降到sigma平方N，

168
00:05:53,930 --> 00:05:56,370
and plug them into here, and
并将其插入在这里，

169
00:05:56,690 --> 00:05:57,640
you know, plug them into this
你知道，将它们插入此

170
00:05:57,760 --> 00:05:59,580
covariance matrix, then the
协方差矩阵，则

171
00:05:59,990 --> 00:06:01,130
two models are actually identical.
两个模型实际上是相同的。

172
00:06:01,630 --> 00:06:02,560
That is, this new model,
也就是说，这种新的模型，

173
00:06:06,210 --> 00:06:07,530
using a multivariate Gaussian distribution,
使用多变量高斯分布，

174
00:06:08,820 --> 00:06:10,340
corresponds exactly to the
完全对应

175
00:06:10,400 --> 00:06:11,510
old model, if the covariance
旧的模式，如果协方差

176
00:06:12,040 --> 00:06:13,700
matrix sigma, has only
矩阵的标准差，只有

177
00:06:14,230 --> 00:06:15,490
0 elements off the diagonals,
0元折对角线，

178
00:06:15,580 --> 00:06:17,700
and in pictures that
并且在图片的

179
00:06:18,180 --> 00:06:19,570
corresponds to having Gaussian distributions,
对应于具有高斯分布，

180
00:06:20,720 --> 00:06:22,260
where the contours of this
其中该轮廓

181
00:06:22,950 --> 00:06:25,620
distribution function are axis aligned.
分布函数轴线对齐。

182
00:06:25,940 --> 00:06:28,500
So you aren't allowed to model the correlations between the diffrent features.
所以你不允许模型的不同特征之间的相关性。

183
00:06:30,990 --> 00:06:32,520
So in that sense the original model
所以在这个意义上的原始模型

184
00:06:33,030 --> 00:06:35,840
is actually a special case of this multivariate Gaussian model.
其实这个多元高斯模型的一个特例。

185
00:06:38,370 --> 00:06:40,370
So when would you use each of these two models?
你什么时候会使用这两类模型？

186
00:06:40,830 --> 00:06:41,750
So when would you the original
所以，当你的原始

187
00:06:42,070 --> 00:06:42,880
model and when would you use
模型，你会用时

188
00:06:43,040 --> 00:06:45,170
the multivariate Gaussian model?
多变量高斯模型？

189
00:06:52,110 --> 00:06:53,670
The original model is probably
原始模型可能是

190
00:06:54,240 --> 00:06:55,840
used somewhat more often,
使用较为频繁，

191
00:06:58,800 --> 00:07:03,160
and whereas the multivariate Gaussian
而多元高斯

192
00:07:03,160 --> 00:07:04,470
distribution is used somewhat
分布用的有点

193
00:07:04,800 --> 00:07:06,670
less but it has the advantage of being
少，但它具有的优势在于

194
00:07:07,000 --> 00:07:08,290
able to capture correlations between features. So
能够捕捉功能之间的相关性。所以

195
00:07:10,490 --> 00:07:11,600
suppose you want to
假设你想

196
00:07:11,770 --> 00:07:13,100
capture anomalies where you
捕捉异常，你

197
00:07:13,210 --> 00:07:14,430
have different features say where
有不同的特征如

198
00:07:14,640 --> 00:07:16,560
features x1, x2 take
特征为x1，x2等

199
00:07:16,790 --> 00:07:19,760
on unusual combinations of values
不同的值的组合。

200
00:07:20,070 --> 00:07:21,320
so in the earlier
因此，在早期的

201
00:07:21,730 --> 00:07:27,320
example, we had that example where the anomaly was with the CPU load and the memory use taking on unusual combinations of values, if
例如，我们有这样的样本，其中的异常是与CPU的负载，并采取对价值观的不同寻常的组合，内存使用，如果

202
00:07:30,240 --> 00:07:31,220
you want to use the original
要使用原始

203
00:07:31,490 --> 00:07:33,500
model to capture that, then what you
模型捕捉到这一点，那么你

204
00:07:33,650 --> 00:07:34,650
need to do is create an
需要做的是创建一个

205
00:07:34,790 --> 00:07:36,780
extra feature, such as X3
额外的特征，如X3

206
00:07:37,020 --> 00:07:40,710
equals X1/X2, you know
等于X1/X2，你知道

207
00:07:40,860 --> 00:07:46,480
equals maybe the CPU load divided by the memory used, or something, and you
也许等于CPU的负载所使用的内存，还是分了，你

208
00:07:47,910 --> 00:07:49,030
need to create extra features
需要创建额外的特征

209
00:07:49,550 --> 00:07:51,440
if there's unusual combinations of values
如果有的同的值组合

210
00:07:51,540 --> 00:07:52,930
where X1 and X2 take
其中X1和X2取

211
00:07:53,220 --> 00:07:54,900
on an unusual combination of
在一个不同的组合

212
00:07:55,000 --> 00:07:56,360
values even though X1 by
值，即使通过X1

213
00:07:56,530 --> 00:07:58,610
itself and X2 by itself
本身和X2本身

214
00:07:59,850 --> 00:08:03,530
looks like it's taking a perfectly normal value. But if you're willing to spend the time to manually
看起来像它采取了完全正常的值。但是，如果你愿意花时间去手动

215
00:08:04,030 --> 00:08:05,240
create an extra feature like this,
创建这样一个额外的特征，

216
00:08:05,920 --> 00:08:07,670
then the original model will work
那么原始模型将工作

217
00:08:07,890 --> 00:08:14,170
fine.  Whereas in contrast, the multivariate Gaussian model can automatically capture
得很好。而与此相反，多元高斯模型可以自动捕获

218
00:08:14,780 --> 00:08:23,360
correlations between different features. But the original model has some other more significant advantages, too, and one huge
不同特征之间的相关性。但原始模型有一些其他更显著的优势，比如

219
00:08:23,740 --> 00:08:24,990
advantage of the original model
利用原始模型

220
00:08:28,200 --> 00:08:29,400
is that it is computationally cheaper, and another view on this
在于，它在计算上是便宜的，并且另一方面

221
00:08:29,650 --> 00:08:31,170
is that is scales better to
是尺度比较好

222
00:08:31,290 --> 00:08:32,720
very large values of n
当n是个非常大的值

223
00:08:32,800 --> 00:08:34,270
and very large numbers of
和非常大的数字

224
00:08:34,460 --> 00:08:36,260
features, and so even
特征，并且因此即使

225
00:08:36,510 --> 00:08:38,090
if n were ten thousand,
如果n分别为10000，

226
00:08:39,470 --> 00:08:40,350
or even if n were equal
甚至如果n是等于

227
00:08:40,990 --> 00:08:42,600
to a hundred thousand, the original
十万，

228
00:08:42,820 --> 00:08:47,120
model will usually work just fine.
原始模型通常会工作得很好。

229
00:08:47,940 --> 00:08:48,930
Whereas in contrast for the multivariate Gaussian model notice here, for
而与此相反，多元高斯模型在这里，

230
00:08:49,070 --> 00:08:49,940
example, that we need to
例如，我们需要

231
00:08:50,440 --> 00:08:51,730
compute the inverse of the matrix
计算该矩阵的逆矩阵

232
00:08:52,110 --> 00:08:53,760
sigma where sigma is
sigma是

233
00:08:54,100 --> 00:08:55,230
an n by n matrix
一个n×n矩阵

234
00:08:56,300 --> 00:08:57,830
and so computing sigma if
所以要计算出sigma，如果

235
00:08:58,160 --> 00:08:59,950
sigma is a hundred thousand by a
sigma是一个十万了

236
00:09:00,190 --> 00:09:02,910
hundred thousand matrix that is going to be very computationally expensive.
十万矩阵，该矩阵将是非常耗时的计算。

237
00:09:03,440 --> 00:09:04,650
And so the multivariate Gaussian model
这样一来，多元高斯模型

238
00:09:05,350 --> 00:09:06,900
scales less well to large
尺度不那么大

239
00:09:07,180 --> 00:09:09,210
values of N. And
N的和值

240
00:09:09,490 --> 00:09:11,030
finally for the original
最后，关于

241
00:09:11,250 --> 00:09:12,630
model, it turns out
原始模型，事实证明

242
00:09:12,770 --> 00:09:13,850
to work out ok even if
就ok了工作，即使

243
00:09:14,090 --> 00:09:15,520
you have a relatively small training
你有一个比较小的训练

244
00:09:15,960 --> 00:09:17,010
set this is the small unlabeled
集这是小的未标记

245
00:09:17,410 --> 00:09:19,130
examples that we use to model p of x
样本我们用来对模型P(x)来建模

246
00:09:20,410 --> 00:09:21,600
of course, and this works fine, even if
当然，这工作得很好，即使

247
00:09:21,720 --> 00:09:23,400
M is, you
M的值是，你

248
00:09:24,530 --> 00:09:25,150
know, maybe 50, 100, works fine.
知道，也许50，100，工作得很好。

249
00:09:25,860 --> 00:09:27,740
Whereas for the multivariate Gaussian, it
而对于多变量高斯分布，它

250
00:09:27,890 --> 00:09:29,340
is sort of a mathematical property
是一种数学性质

251
00:09:29,980 --> 00:09:31,230
of the algorithm that you must have m
你必须有m

252
00:09:32,100 --> 00:09:38,810
greater than n, so that the number of examples is greater than the number of features you have. And there's a mathematical property of the way we estimate the parameters
大于n，因此，样本的数目是大于的特征数的。还有的，我们估计参数的方法的数学属性

253
00:09:41,840 --> 00:09:43,850
that if this is not true, so if m is less than or equal to n,
如果这是不正确的，因此，如果m小于或等于n，

254
00:09:44,730 --> 00:09:51,610
then this matrix isn't even invertible, that is this matrix is singular, and so you can't even use the
那么这个矩阵甚至不是可逆的，即该矩阵是奇异的，所以你甚至不能使用

255
00:09:51,810 --> 00:09:53,230
multivariate Gaussian model unless you make some changes to it. But a
多元高斯模型，除非你做一些修改。但

256
00:09:54,630 --> 00:09:55,820
typical rule of thumb
这个典型的规则

257
00:09:56,030 --> 00:09:58,760
that I use is, I will use the
我用的就是，我将使用

258
00:09:58,860 --> 00:10:00,500
multivariate Gaussian model only if m is much greater than n, so this is sort of the
多元高斯模型仅当m是大于n大得多，所以这是一种

259
00:10:04,050 --> 00:10:05,750
narrow mathematical requirement, but
狭隘的数学要求，但

260
00:10:05,900 --> 00:10:07,300
in practice, I would use
在实践中，我会用

261
00:10:07,480 --> 00:10:08,910
the multivariate Gaussian model, only
多变量高斯模型，只

262
00:10:09,280 --> 00:10:10,420
if m were quite a bit
如果m是有点点

263
00:10:10,750 --> 00:10:11,870
bigger than n.  So if
大于n大。所以，如果

264
00:10:12,040 --> 00:10:13,320
m were greater than or
m大于或

265
00:10:13,470 --> 00:10:14,780
equal to 10 times n, let's
等于10 n次，让我们

266
00:10:14,990 --> 00:10:16,460
say, might be a reasonable rule of thumb, and if
比方说，可能还是一个合理的经验法则，如果

267
00:10:18,970 --> 00:10:20,890
it doesn't satisfy this, then the multivariate Gaussian model
它不满足这一点，那么多元高斯模型

268
00:10:21,300 --> 00:10:23,320
has a lot
有很多

269
00:10:23,700 --> 00:10:25,850
of parameters, right, so this covariance matrix sigma is an n by n matrix,
的参数，所以这个协方差矩阵sigma是一个n×n矩阵，

270
00:10:26,510 --> 00:10:27,590
so it has, you know, roughly
所以，你知道的，大概

271
00:10:27,820 --> 00:10:31,230
n squared parameters, because it's a symmetric matrix,
n平方的参数，因为它是一个对称矩阵，

272
00:10:31,710 --> 00:10:33,040
it's actually closer to n squared
它实际上更接近到n的平方

273
00:10:33,430 --> 00:10:35,230
over 2 parameters, but this is a
以上2个参数，但是这是一个

274
00:10:35,670 --> 00:10:37,220
lot of parameters, so you need
很多的参数，所以你需要

275
00:10:37,600 --> 00:10:38,720
make sure you have a fairly
确保你有一个相当

276
00:10:38,930 --> 00:10:48,350
large value for m, make sure you have enough data to fit all these parameters. And m greater than
大的值给m，请确保您有足够的数据，以适应所有这些参数。m大于

277
00:10:49,010 --> 00:10:52,220
or equal to 10 n would be a reasonable rule of thumb to make sure that you can estimate this covariance matrix sigma reasonably well.
或等于10 N将是一个经验合理的规则，以确保您能够估计这个协方差矩阵sigma还算不错。

278
00:10:55,090 --> 00:10:56,240
So in practice the original
因此在实践中，原始模型

279
00:10:56,750 --> 00:10:58,940
model shown on the left that is used more often.
显示上左边的更常用。

280
00:10:59,520 --> 00:11:00,840
And if you suspect that you
如果您怀疑自己

281
00:11:01,060 --> 00:11:02,680
need to capture correlations between features
需要捕捉特征之间的相关性

282
00:11:03,450 --> 00:11:08,150
what people will often do is just manually design extra features like these to capture specific
人们会经常做的只是手动设计像这些额外的特征来捕捉特定

283
00:11:08,780 --> 00:11:13,020
unusual combinations of values. But in problems where you
值的不同寻常的组合。但问题在那里你

284
00:11:13,120 --> 00:11:15,310
have a very large training set or m is very large and n is
有一个非常大的训练集或m是非常大的，n是

285
00:11:17,700 --> 00:11:20,160
not too large, then the multivariate Gaussian
不要过大，那么多元高斯

286
00:11:20,520 --> 00:11:21,720
model is well worth considering and may work better as well, and can
模型是非常值得考虑，可能更好地工作为好，并能

287
00:11:24,360 --> 00:11:25,960
save you from having to
节省您不必

288
00:11:26,070 --> 00:11:27,400
spend your time to manually
花你的时间来手动

289
00:11:28,070 --> 00:11:30,350
create extra features in case
在情况下创建额外的特征

290
00:11:31,380 --> 00:11:33,520
the anomalies turn out to be captured by unusual
异常变成了异常被捕获

291
00:11:34,040 --> 00:11:35,790
combinations of values of the features.
的特征值的组合。

292
00:11:37,430 --> 00:11:38,330
Finally I just want to
最后，我只是想

293
00:11:38,600 --> 00:11:40,220
briefly mention one somewhat technical
简要地提一个有点技术

294
00:11:40,770 --> 00:11:42,200
property, but if you're
属性，但如果你

295
00:11:42,370 --> 00:11:43,210
fitting multivariate Gaussian
拟合多元高斯

296
00:11:43,690 --> 00:11:44,590
model, and if you find
模型，如果你发现

297
00:11:44,910 --> 00:11:46,340
that the covariance matrix sigma
该协方差矩阵sigma

298
00:11:47,150 --> 00:11:48,160
is singular, or you find
是奇异的，或您发现

299
00:11:48,340 --> 00:11:51,340
it's non-invertible, they're usually 2 cases for this.
它是不可逆的，他们通常是两种情况。

300
00:11:51,680 --> 00:11:52,990
One is if it's failing to
其一是如果它未能

301
00:11:53,100 --> 00:11:54,270
satisfy this m greater than
满足这个m大于

302
00:11:54,640 --> 00:11:56,200
n condition, and the
n的条件，以及

303
00:11:56,570 --> 00:11:58,970
second case is if you have redundant features.
第二种情况是，如果你有多余的特征。

304
00:11:59,570 --> 00:12:00,980
So by redundant features, I mean,
因此，通过多余的特征，我的意思是，

305
00:12:01,520 --> 00:12:02,760
if you have 2 features that are the same.
如果你有2个特征是相同的。

306
00:12:02,980 --> 00:12:04,700
Somehow you accidentally made two
不知怎的，你不小心做了两个

307
00:12:04,830 --> 00:12:11,220
copies of the feature, so your x1 is just equal to x2. Or if you have redundant features like maybe
该特征的拷贝，所以你的X1正好等于2倍。或者如果你有多余的特征，如可能

308
00:12:12,860 --> 00:12:14,920
your features X3 is equal to feature X4, plus feature X5.
你的特征X3是等于X4的特征，再加上特征X5。

309
00:12:15,870 --> 00:12:16,960
Okay, so if you have highly
好了，所以如果你有高度

310
00:12:17,250 --> 00:12:18,500
redundant features like these, you
多余的特征，如这些，你

311
00:12:18,680 --> 00:12:20,110
know, where if X3 is equal
知道，其中如果X 3是相等

312
00:12:20,380 --> 00:12:21,840
to X4 plus X5, well X3
到X4加X5，X3以及

313
00:12:22,350 --> 00:12:24,420
doesn't contain any extra information, right?
不包含任何额外的信息，对不对？

314
00:12:24,590 --> 00:12:26,460
You just take these 2 other features, and add them together.
你只需要这2个其他的特征，并把它们相加。

315
00:12:27,590 --> 00:12:28,900
And if you have this
如果你有这样的

316
00:12:29,030 --> 00:12:30,960
sort of redundant features, duplicated features,
多余特征，重复特征，

317
00:12:31,520 --> 00:12:34,030
or this sort of features, than sigma may be non-invertible.
或这样的特征，sigma可以是不可逆的。

318
00:12:35,060 --> 00:12:37,000
And so there's a debugging set--
所以有一个调试设置 -

319
00:12:37,340 --> 00:12:38,270
this should very rarely happen,
这应该很少发生，

320
00:12:38,750 --> 00:12:40,190
so you probably won't run into this,
所以你可能不会遇到这个，

321
00:12:40,250 --> 00:12:42,780
it is very unlikely that you have to worry about this--
它是不太可能，你不必担心这一点 -

322
00:12:42,940 --> 00:12:44,480
but in case you implement a
但如果你实现一个

323
00:12:44,780 --> 00:12:46,850
multivariate Gaussian model you find that sigma is non-invertible.
多元高斯模型，你发现，sigma是不可逆的。

324
00:12:48,240 --> 00:12:49,350
What I would do is first
我会做的是第一

325
00:12:49,880 --> 00:12:51,300
make sure that M is quite
确保M比

326
00:12:51,540 --> 00:12:53,520
a bit bigger than N, and if it
N大很多，如果它

327
00:12:53,670 --> 00:12:54,640
is then, the second thing I
然后，第二件事情我

328
00:12:54,760 --> 00:12:56,560
do, is just check for redundant features.
这样做，只是检查多余特征。

329
00:12:57,360 --> 00:12:58,070
And so if there are 2 features
所以，如果有2个特点

330
00:12:58,150 --> 00:12:59,360
that are equal, just get rid
这是相等的，只是去掉

331
00:12:59,480 --> 00:13:00,590
of one of them, or if
其中之一，或者如果

332
00:13:00,970 --> 00:13:02,580
you have redundant if these
你有多余的，如果这些

333
00:13:02,880 --> 00:13:04,100
, X3 equals X4 plus X5,
，X3等于X4加X5，

334
00:13:04,490 --> 00:13:05,160
just get rid of the redundant
刚刚去掉多余的

335
00:13:05,720 --> 00:13:08,650
feature, and then it should work fine again.
特征，那么它应该正常工作。

336
00:13:08,840 --> 00:13:09,610
As an aside for those of you
顺便说一句，对于那些你们

337
00:13:09,840 --> 00:13:11,210
who are experts in linear algebra,
线性代数专家，

338
00:13:11,810 --> 00:13:13,280
by redundant features, what I
通过多余的特征，我

339
00:13:13,410 --> 00:13:14,970
mean is the formal term is
意思是先前的方程的

340
00:13:15,300 --> 00:13:17,680
features that are linearly dependent.
特征是线性相关的。

341
00:13:18,460 --> 00:13:19,180
But in practice what that really means
但在实践中是什么真正含义

342
00:13:19,620 --> 00:13:21,710
is one of these problems tripping
是这些问题的难为

343
00:13:22,040 --> 00:13:24,130
up the algorithm if you just make you features non-redundant.,
你的算法，如果你只是让你的特征非多余。，

344
00:13:24,790 --> 00:13:26,390
that should solve the problem of sigma being non-invertable.
应该解决的sigma是不可逆的问题。

345
00:13:26,720 --> 00:13:29,100
But once again
但再次

346
00:13:29,530 --> 00:13:30,630
the odds of your running into this
你的遇到这个的概率

347
00:13:30,850 --> 00:13:32,190
at all are pretty low so
在所有都相当低，因此

348
00:13:32,540 --> 00:13:33,800
chances are, you can
这样的机会，你可以

349
00:13:34,130 --> 00:13:35,460
just apply the multivariate Gaussian
只是采用了多元高斯

350
00:13:35,990 --> 00:13:37,240
model, without having to
模型中，而不必

351
00:13:37,450 --> 00:13:39,150
worry about sigma being non-invertible,
担心sigma是不可逆的，

352
00:13:40,090 --> 00:13:41,180
so long as m is greater
只要m为大于

353
00:13:41,470 --> 00:13:42,780
than or equal to n. So
小于或等于n。所以

354
00:13:43,200 --> 00:13:45,180
that's it for anomaly detection,
这是它的异常检测，

355
00:13:45,810 --> 00:13:47,230
with the multivariate Gaussian distribution.
用多元高斯分布。

356
00:13:48,220 --> 00:13:49,240
And if you apply this method
如果你将这个方法

357
00:13:49,950 --> 00:13:51,160
you would be able to have an
你将能够有一个

358
00:13:51,310 --> 00:13:53,250
anomaly detection algorithm that automatically
异常检测算法，自动

359
00:13:54,010 --> 00:13:55,430
captures positive and negative
捕获正和负

360
00:13:55,610 --> 00:13:56,690
correlations between your different
您的不同特征之间的相关性

361
00:13:57,030 --> 00:13:58,520
features and flags an anomaly
和标志异常

362
00:13:59,450 --> 00:14:00,820
if it sees is unusual combination
如果它认为是不寻常的组合

363
00:14:01,630 --> 00:14:02,770
of the values of the features.
的特征的值。

