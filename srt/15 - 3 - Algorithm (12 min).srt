1
00:00:00,090 --> 00:00:01,240
In the last video, we talked
在上一节视频中
(字幕整理：中国海洋大学 黄海广,haiguang2000@qq.com )

2
00:00:01,560 --> 00:00:03,660
about the Gaussian distribution. In
我们谈到了高斯分布

3
00:00:03,810 --> 00:00:05,350
this video lets apply that
在本节视频中

4
00:00:05,440 --> 00:00:07,300
to develop an anomaly detection algorithm.
我将应用高斯分布开发异常检测算法

5
00:00:10,360 --> 00:00:11,690
Let's say that we have an
假如说我们有一个无标签的训练集

6
00:00:11,840 --> 00:00:13,390
unlabeled training set of M
共有 m 个训练样本

7
00:00:13,650 --> 00:00:15,410
examples, and each of
并且

8
00:00:15,470 --> 00:00:16,730
these examples is going to
这里的训练集里的每一个样本

9
00:00:16,760 --> 00:00:18,350
be a feature in Rn so
都是 n 维的特征

10
00:00:18,440 --> 00:00:19,420
your training set could be,
因此你的训练集应该是

11
00:00:20,540 --> 00:00:21,860
feature vectors from the last
它可以是来自上一个这些特征向量的集合

12
00:00:22,730 --> 00:00:24,150
M aircraft engines being manufactured.
比如 m 个飞机引擎产品的样本

13
00:00:24,960 --> 00:00:26,730
Or it could be features from m
或者是

14
00:00:27,070 --> 00:00:28,290
users or something else.
来自 m 个用户或者其它的什么东西

15
00:00:29,320 --> 00:00:30,460
The way we are going to address
现在

16
00:00:30,840 --> 00:00:32,310
anomaly detection, is we are
我们解决异常检测的方法是

17
00:00:32,350 --> 00:00:33,480
going to model p of x
我们要从数据中

18
00:00:33,860 --> 00:00:35,640
from the data sets.
建立一个 p(x) 概率模型

19
00:00:36,240 --> 00:00:38,530
We're going to try to figure out what are high probability features, what
我们要尝试计算出这些哪些特征出现的概率比较高

20
00:00:38,860 --> 00:00:40,620
are lower probability types of features.
哪些特征的概率较低

21
00:00:41,350 --> 00:00:42,810
So, x is a
因此

22
00:00:43,090 --> 00:00:44,900
vector and what we
x 是一个向量

23
00:00:45,320 --> 00:00:46,580
are going to do is model p of
我们要做的事情是

24
00:00:47,020 --> 00:00:48,870
x, as probability of x1,
建立一个 p(x) 的模型 表示 x1 的概率

25
00:00:49,440 --> 00:00:50,390
that is of the first component
这是 x 的第一个组成部分

26
00:00:50,950 --> 00:00:53,180
of x, times the probability
并用它乘以 x2 的概率

27
00:00:53,990 --> 00:00:54,960
of x2, that is the probability
这是第二个特征的概率

28
00:00:55,510 --> 00:00:57,350
of the second feature, times the
然后再乘以

29
00:00:57,450 --> 00:00:58,860
probability of the third
第三个特征的概率

30
00:00:59,090 --> 00:01:01,230
feature, and so on up
一直这样下去

31
00:01:01,410 --> 00:01:03,290
to the probability of the final feature
直到最后一个特征

32
00:01:03,760 --> 00:01:03,930
of Xn.
特征 xn

33
00:01:04,200 --> 00:01:06,320
Now I'm leaving space here cause I'll fill in something in a minute.
这里我先空着 最后再来填满

34
00:01:08,780 --> 00:01:09,720
So, how do we
那么

35
00:01:09,830 --> 00:01:10,960
model each of these terms,
我们如何为这些项进行建模呢？

36
00:01:11,460 --> 00:01:13,020
p of X1, p of X2, and so on.
p(x1) p(x2) 等等

37
00:01:14,080 --> 00:01:15,380
What we're going to do,
我们下面要做的

38
00:01:15,680 --> 00:01:16,860
is assume that the feature,
是假定特征 x1

39
00:01:17,480 --> 00:01:19,830
X1, is distributed according
其分布

40
00:01:20,340 --> 00:01:22,950
to a Gaussian distribution, with
服从高斯正态分布

41
00:01:23,160 --> 00:01:25,140
some mean, which you
你也可以

42
00:01:25,340 --> 00:01:25,850
want to write as mu1 and
写出期望 μ1

43
00:01:25,920 --> 00:01:26,900
some variance, which I'm going
以及方差

44
00:01:26,990 --> 00:01:28,560
to write as sigma squared 1,
我用 σ1 的平方表示

45
00:01:29,890 --> 00:01:30,690
and so p of X1 is
这样

46
00:01:30,820 --> 00:01:32,020
going to be a Gaussian
p(x1) 就可以写成

47
00:01:32,350 --> 00:01:34,410
probability distribution, with mean
这样一个高斯分布

48
00:01:34,610 --> 00:01:37,580
mu1 and variance sigma squared 1.
其期望为 μ1 方差为 (σ1)^2

49
00:01:38,230 --> 00:01:39,660
And similarly I'm
同样地

50
00:01:39,720 --> 00:01:40,570
going to assume that X2
我假设 x2

51
00:01:40,760 --> 00:01:42,220
is distributed, Gaussian,
也服从高斯分布

52
00:01:42,870 --> 00:01:44,620
that's what this little tilda stands for,
这里的小波浪线读作"服从"

53
00:01:44,800 --> 00:01:47,220
that means distributed Gaussian
表示它服从高斯分布

54
00:01:47,740 --> 00:01:49,490
with mean mu2 and Sigma
其期望为 μ2

55
00:01:49,830 --> 00:01:51,780
squared 2, so it's distributed according
方差为 (σ2)^2

56
00:01:52,170 --> 00:01:54,230
to a different Gaussian, which has
所以它服从的高斯分布与刚刚那个不同

57
00:01:54,460 --> 00:01:58,010
a different set of parameters, mu2 sigma square 2.
它的期望和方差都不一样

58
00:01:58,120 --> 00:02:00,160
And similarly, you know,
与此类似

59
00:02:00,360 --> 00:02:04,020
X3 is yet another
x3 服从另外一个高斯分布

60
00:02:04,480 --> 00:02:06,590
Gaussian, so this
因此

61
00:02:06,780 --> 00:02:09,100
can have a different mean and
x3 也会有一个不同的期望

62
00:02:09,300 --> 00:02:11,630
a different standard deviation than the
以及一个与其它特征不同的标准差

63
00:02:11,830 --> 00:02:15,370
other features, and so on, up to XN.
直到 xn 都是如此

64
00:02:17,000 --> 00:02:17,740
And so that's my model.
这就是我要说的模型

65
00:02:19,010 --> 00:02:20,230
Just as a side comment for
顺便说一下

66
00:02:20,370 --> 00:02:21,490
those of you that are experts in
对那些擅长统计的同学来说

67
00:02:21,890 --> 00:02:22,770
statistics, it turns out that
实际上

68
00:02:22,990 --> 00:02:23,850
this equation that I just
我刚刚写的式子

69
00:02:24,250 --> 00:02:25,590
wrote out actually corresponds to an
写出来实际上就对应于

70
00:02:25,750 --> 00:02:27,490
independence assumption on the
一个从 x1 到 xn 上的独立的假设

71
00:02:28,060 --> 00:02:29,550
values of the features x1 through xn.
一个从 x1 到 xn 上的独立的假设

72
00:02:30,290 --> 00:02:31,520
But in practice it turns out
但实际中 结果是

73
00:02:32,040 --> 00:02:34,010
that the algorithm of this fragment, it works just fine,
这些算法的效果都还不错

74
00:02:34,410 --> 00:02:36,330
whether or not these features are
无论这些特征

75
00:02:36,610 --> 00:02:37,780
anywhere close to independent and
是否独立

76
00:02:38,280 --> 00:02:39,810
even if independence assumption doesn't
即使这个独立的假设不成立

77
00:02:40,240 --> 00:02:41,830
hold true this algorithm works just fine.
这个算法的效果也还不错

78
00:02:42,650 --> 00:02:45,870
But in case you don't know
如果你不知道

79
00:02:45,970 --> 00:02:47,380
those terms I just used independence assumptions and so on,
我刚刚提到的独立假说和其它相关内容

80
00:02:47,830 --> 00:02:48,460
don't worry about it.
也不要担心

81
00:02:49,170 --> 00:02:50,840
You'll be able to understand
你将会慢慢有能力去理解

82
00:02:51,360 --> 00:02:52,690
it and implement this algorithm just fine
并且能很好地实现这些算法

83
00:02:53,250 --> 00:02:55,310
and that comment was really meant only for the experts in statistics.
刚才插入的那些内容也不重要

84
00:02:57,790 --> 00:02:58,880
Finally, in order to
最后

85
00:02:59,210 --> 00:03:00,320
wrap this up, let me
做一个总结

86
00:03:00,590 --> 00:03:04,680
take this expression and write it a little bit more compactly.
让我把这些式子写得紧凑点

87
00:03:05,120 --> 00:03:06,200
So, we're going to
我可以把这个式子

88
00:03:06,310 --> 00:03:07,500
write this is a product
写成一个乘积式

89
00:03:07,740 --> 00:03:09,520
from J equals one
从 j=1 到 j=n

90
00:03:10,230 --> 00:03:11,840
through N, of P
从 j=1 到 j=n

91
00:03:12,140 --> 00:03:15,350
of XJ parameterized by
被muj和( ∑2 )^2

92
00:03:16,020 --> 00:03:17,930
mu j comma sigma squared
乘积项是 p(xj; μj,  (σj)^2)

93
00:03:19,500 --> 00:03:21,500
j. So this funny
在这里

94
00:03:21,790 --> 00:03:23,330
symbol here, there is
出现了一个有趣的符号

95
00:03:23,780 --> 00:03:25,220
capital Greek alphabet pi,
希腊字母 π

96
00:03:25,490 --> 00:03:27,600
that funny symbol there corresponds to
这个有趣的字母表示的是

97
00:03:28,190 --> 00:03:29,980
taking the product of a set of values.
一系列数值的乘积

98
00:03:30,590 --> 00:03:32,290
And so, you're familiar with
同时

99
00:03:32,400 --> 00:03:33,930
the summation notation, so the
你应该对求和符号比较熟悉

100
00:03:34,520 --> 00:03:36,460
sum from i equals one through
从 i=1 到 n 求和

101
00:03:36,930 --> 00:03:39,070
n, of i. This
也就是

102
00:03:39,960 --> 00:03:41,820
means 1 + 2 + 3 plus
1+2+3+...

103
00:03:42,230 --> 00:03:43,730
dot dot dot, up to
直到加到 n

104
00:03:43,910 --> 00:03:45,350
n. Where as this
正如刚才的符号 π

105
00:03:45,660 --> 00:03:46,910
funny symbol here, this product
这个求和符号 ∑

106
00:03:47,390 --> 00:03:48,630
symbol, right product from i
只是表示从 i 等于1

107
00:03:48,840 --> 00:03:50,310
equals 1 through n
到 n 进行连加

108
00:03:50,620 --> 00:03:52,210
of i.  Then this
那么

109
00:03:52,520 --> 00:03:54,530
means that, it's just like summation except that we're now multiplying.
这里的 π 也是一样 只不过表示连乘而不是连加

110
00:03:55,200 --> 00:03:56,680
This becomes 1 times
这就变成了

111
00:03:56,880 --> 00:03:58,700
2 times 3 times up
1×2×3 一直乘到 n

112
00:03:59,910 --> 00:04:01,330
to N. And so using
所以这里用的就是

113
00:04:01,860 --> 00:04:03,430
this product notation, this
这里连乘的符号

114
00:04:03,570 --> 00:04:05,880
product from j equals 1 through n of this expression.
这个表达式表示从等于 j=1 开始一直乘到 j=n

115
00:04:06,620 --> 00:04:08,440
It's just more compact, it's
这样写看起来更紧凑

116
00:04:08,820 --> 00:04:09,960
just shorter way for writing
这样写只是避免了

117
00:04:10,330 --> 00:04:12,810
out this product of
把这个乘积表达式

118
00:04:13,120 --> 00:04:14,400
of all of these terms up there.
的所有项都写出来而已

119
00:04:15,200 --> 00:04:16,200
Since we're are taking these p
因为我们是采用

120
00:04:16,430 --> 00:04:17,510
of x j given mu j
给出mu j、∑( j )的p和xj

121
00:04:17,730 --> 00:04:18,740
comma sigma squared j terms
以及

122
00:04:19,130 --> 00:04:20,290
and multiplying them together.
和它们的乘积项

123
00:04:21,540 --> 00:04:22,830
And, by the way the problem
同时 顺便要说的是

124
00:04:23,250 --> 00:04:25,370
of estimating this distribution
估计x及p的分布的问题

125
00:04:25,990 --> 00:04:27,130
p of x, they're sometimes called
这种问题通常被称为

126
00:04:28,280 --> 00:04:29,540
the problem of density estimation.
密度估计问题

127
00:04:30,420 --> 00:04:31,270
Hence the title of the slide.
正如幻灯片的标题上写的

128
00:04:33,800 --> 00:04:35,310
So putting everything together, here
把所有的整合到一起

129
00:04:35,500 --> 00:04:36,920
is our anomaly detection algorithm.
下面便是我们的异常检测算法

130
00:04:38,120 --> 00:04:40,290
The first step is to choose
第一步便是选择特征

131
00:04:40,650 --> 00:04:41,600
features, or come up with
或者是提出一些

132
00:04:41,700 --> 00:04:42,740
features xi that we think
我们认为其指数比较反常的样本

133
00:04:43,040 --> 00:04:45,340
might be indicative of anomalous examples.
的特征Xi

134
00:04:46,050 --> 00:04:47,020
So what I mean by that,
因此 我的意思是

135
00:04:47,240 --> 00:04:48,490
is, try to come
可以尝试着

136
00:04:48,680 --> 00:04:49,990
up with features, so that when there's
提出一些特征

137
00:04:50,280 --> 00:04:51,630
an unusual user in your
通过某些

138
00:04:52,190 --> 00:04:53,000
system that may be doing
在你的系统里的不同学寻常的用户

139
00:04:53,190 --> 00:04:54,790
fraudulent things, or when the
的反常和欺诈行为

140
00:04:55,020 --> 00:04:56,670
aircraft engine examples, you know
或者是那个飞机引擎的例子

141
00:04:56,760 --> 00:04:59,500
there's something funny, something strange about one of the aircraft engines.
在飞机的众多引擎里有一个奇怪的引擎

142
00:05:00,280 --> 00:05:01,230
Choose features X I, that
选择特征Xi

143
00:05:02,000 --> 00:05:03,330
you think might take on unusually
这个特征可能会

144
00:05:04,410 --> 00:05:05,860
large values, or unusually
呈现一个不同寻常特别大的数值

145
00:05:06,020 --> 00:05:08,750
small values, for what an
或者特别小的数值

146
00:05:08,880 --> 00:05:10,160
anomalous example might look like.
因为这个看起来本身就有些异常

147
00:05:10,910 --> 00:05:12,440
But more generally, just try
但更为普遍的是

148
00:05:12,690 --> 00:05:14,340
to choose features that describe general
尽可能尝试选择用来

149
00:05:16,160 --> 00:05:19,380
properties of the things that you're collecting data on.
描述这些收集的数据相关的属性的事情

150
00:05:20,030 --> 00:05:21,360
Next, given a training set,
下一步是给出训练集

151
00:05:22,020 --> 00:05:23,980
of M, unlabled examples,
以及没有标记的样本

152
00:05:25,000 --> 00:05:26,980
X1 through X M, we
从X1到X

153
00:05:27,170 --> 00:05:28,580
then fit the parameters,
我们从mu1到mun

154
00:05:29,090 --> 00:05:30,170
mu 1 through mu n, and
找出里面合适的参数

155
00:05:30,340 --> 00:05:31,480
sigma squared 1 through sigma
从σ1的平方到σn的平方

156
00:05:31,690 --> 00:05:33,460
squared n, and so these
同时

157
00:05:33,840 --> 00:05:34,810
were the formulas similar to
这些公式

158
00:05:34,840 --> 00:05:36,420
the formulas we have
和之前在视频里的

159
00:05:36,680 --> 00:05:37,610
in the previous video, that we're
公式比较相似

160
00:05:37,740 --> 00:05:39,180
going to use the estimate
因此 我们便可以

161
00:05:39,310 --> 00:05:41,120
each of these parameters, and just to give
估计这些参数的值

162
00:05:42,030 --> 00:05:43,670
some interpretation, mu J,
同时 给出对应的解释

163
00:05:44,060 --> 00:05:47,830
that's my average value of the j feature.
muJ是特征j的平均值

164
00:05:48,720 --> 00:05:51,580
Mu j goes in this term p of xj.
muj便在xj的p这项里面

165
00:05:52,440 --> 00:05:53,870
which is parametrized by mu J
被muJ

166
00:05:54,220 --> 00:05:55,590
and sigma squared J. And
σJ的平方参数化

167
00:05:55,920 --> 00:05:57,890
so this says for the
因此

168
00:05:58,360 --> 00:05:59,620
mu J just take the
这对muJ就好比

169
00:05:59,700 --> 00:06:00,720
mean over my training
通过特征j的

170
00:06:01,070 --> 00:06:02,930
set of the values of the j feature.
训练集数据取平均值

171
00:06:03,860 --> 00:06:05,100
And, just to mention, that you
同时

172
00:06:05,220 --> 00:06:07,410
do this, you compute these
计算这些公式从

173
00:06:07,620 --> 00:06:08,830
formulas for j equals
j的值从1到n

174
00:06:09,420 --> 00:06:10,360
one through n. So use
然后

175
00:06:10,700 --> 00:06:11,960
these formulas to estimate mu
用这些公式来估计mu1

176
00:06:12,230 --> 00:06:14,020
1, to estimate mu
再估计mu2

177
00:06:14,070 --> 00:06:15,620
2, and so on up to
直到mun

178
00:06:16,170 --> 00:06:17,460
mu n, and similarly for sigma
同样地 对于σ的平方

179
00:06:17,770 --> 00:06:19,060
squared, and it's also
同时

180
00:06:19,390 --> 00:06:21,530
possible to come up with vectorized versions of these.
对于矢量化的参数特征也可能适用该方法

181
00:06:21,830 --> 00:06:22,900
So if you think of
如果

182
00:06:23,000 --> 00:06:25,220
mu as a vector, so mu
你把mu假想成一个向量

183
00:06:25,920 --> 00:06:27,430
if is a vector there's mu 1,
那么向量mu就有

184
00:06:27,760 --> 00:06:29,230
mu 2, down to mu
mu1到mu2直到mun

185
00:06:29,570 --> 00:06:31,180
n, then a vectorized
那么

186
00:06:31,660 --> 00:06:33,510
version of that set
向量化的参数集合

187
00:06:33,910 --> 00:06:35,530
of parameters can be written
就能被写出来

188
00:06:36,440 --> 00:06:37,830
like so sum from 1
其和值

189
00:06:37,880 --> 00:06:39,610
equals one through n xi.
xi的值从1到n

190
00:06:40,290 --> 00:06:41,290
So, this formula that I
在这个公式中

191
00:06:41,410 --> 00:06:43,530
just wrote out estimates this
我刚刚写出用来估计xi值

192
00:06:43,990 --> 00:06:45,160
xi as the feature vectors
的特征向量

193
00:06:45,660 --> 00:06:48,140
that estimates mu for all the values of n simultaneously.
同时 对不同n的取值 这些向量也可以估计出mu的值来

194
00:06:49,140 --> 00:06:50,070
And it's also possible to come
由此 提出一种

195
00:06:50,430 --> 00:06:52,130
up with a vectorized formula for
针对估计σj的平方的值的

196
00:06:52,290 --> 00:06:55,110
estimating sigma squared j. Finally,
矢量化的公式成为可能

197
00:06:56,500 --> 00:06:57,890
when you're given a new example, so
最后 我们给出一个新案例

198
00:06:58,100 --> 00:06:59,270
when you have a new aircraft engine
当有一个全新的飞机引擎时

199
00:06:59,740 --> 00:07:01,420
and you want to know is this aircraft engine anomalous.
你想要知道这个飞机引擎是否出现异常

200
00:07:02,470 --> 00:07:03,430
What we need to do is then
我们要做的就是

201
00:07:03,570 --> 00:07:05,610
compute p of x, what's the probability of this new example?
计算出x的p值来 那么这个案例中的概率是多少呢

202
00:07:06,790 --> 00:07:07,670
So, p of x is equal
我们知道x的p值

203
00:07:07,990 --> 00:07:09,990
to this product, and
等于这个乘上

204
00:07:10,100 --> 00:07:11,140
what you implement, what you compute,
你现在

205
00:07:11,750 --> 00:07:14,040
is this formula and
正在计算的这个公式

206
00:07:15,000 --> 00:07:16,610
where over here, this thing
就是这个

207
00:07:16,840 --> 00:07:17,900
here this is just the
在这里的这个公式

208
00:07:18,260 --> 00:07:19,250
formula for the Gaussian
是针对计算高斯概率的

209
00:07:19,800 --> 00:07:21,000
probability, so you compute
计算出这一项

210
00:07:21,240 --> 00:07:22,880
this thing, and finally if
最后

211
00:07:22,940 --> 00:07:24,420
this probability is very small,
如果这个概率值很小

212
00:07:24,860 --> 00:07:26,370
then you flag this thing as an anomaly.
那么你就将这一项标注为异常

213
00:07:27,570 --> 00:07:29,380
Here's an example of an application of this method.
这就是我们应用这种方法的一个案例

214
00:07:30,870 --> 00:07:31,860
Let's say we have this data
下面就让我们谈谈

215
00:07:32,210 --> 00:07:35,430
set plotted on the upper left of this slide.
在幻灯片左侧上面绘制的数据集

216
00:07:36,670 --> 00:07:38,860
if you look at this, well, lets look the feature of x1.
如果你看到这个 让我们看这个x1的特征

217
00:07:39,610 --> 00:07:40,640
If you look at this data set, it
囚你看到这个数据集

218
00:07:40,750 --> 00:07:42,600
looks like on average, the features
它看起来比较平均

219
00:07:42,950 --> 00:07:44,330
x1 has a mean of about 5
x1的特征里有一个5个元素的平均值

220
00:07:45,540 --> 00:07:47,420
and the standard deviation, if
并且也有一个标准差

221
00:07:47,590 --> 00:07:48,660
you only look at just the x1
如果你看到了

222
00:07:49,010 --> 00:07:50,030
values of this data set
x1数据集的值

223
00:07:50,310 --> 00:07:51,720
has the standard deviation of maybe 2.
其标准差可能为2

224
00:07:52,370 --> 00:07:55,110
So that sigma 1 and
所以对于σ1

225
00:07:55,460 --> 00:07:57,380
looks like x2 the
以及看起来像

226
00:07:57,670 --> 00:07:59,070
values of the features as
从纵轴测量的

227
00:07:59,250 --> 00:08:00,370
measured on the vertical axis,
特征值x2

228
00:08:00,840 --> 00:08:01,730
looks like it has an average
看起来其平均值

229
00:08:02,010 --> 00:08:03,110
value of about 3, and
可能是3

230
00:08:03,380 --> 00:08:05,750
a standard deviation of about 1. So if
且其标准差值为1

231
00:08:05,880 --> 00:08:06,940
you take this data set and if
如果你使用这个数据集

232
00:08:07,010 --> 00:08:08,690
you estimate mu1, mu2, sigma1,
且如果你估计mu1、mu2、σ1、

233
00:08:09,030 --> 00:08:11,410
sigma2, this is what you get.
σ2 这就是你要求解的

234
00:08:11,610 --> 00:08:12,930
And again, I'm writing sigma here,
再次说明一下 我在这里写的σ

235
00:08:13,140 --> 00:08:14,620
I'm think about standard deviations, but
我在思考关于它的标准差

236
00:08:15,100 --> 00:08:16,240
the formula on the previous 5
但先前用公式算出来是5

237
00:08:16,280 --> 00:08:17,640
actually gave the estimates of the squares
实际上可以将这些项平方再进行计算

238
00:08:18,120 --> 00:08:20,670
of theses things, so sigma squared 1 and sigma squared 2.
这样可得到σ1的平方以及σ2的平方

239
00:08:20,940 --> 00:08:21,920
So, just be careful whether
但是你应该仔细

240
00:08:22,090 --> 00:08:23,260
you are using sigma 1, sigma
你现在是否在使用σ1、

241
00:08:23,380 --> 00:08:25,490
2, or sigma squared 1 or sigma squared 2.
σ2以及期其它的σ的平方项

242
00:08:25,960 --> 00:08:26,700
So, sigma squared 1 of course
所以

243
00:08:26,820 --> 00:08:28,500
would be equal to 4, for
σ1的平方的值当然等于4

244
00:08:31,130 --> 00:08:32,260
example, as the square of 2.
举个例子 2的平方

245
00:08:32,310 --> 00:08:34,010
And in pictures what p of
在图上

246
00:08:34,180 --> 00:08:35,550
x1 parametrized by mu1 and
被mu1和σ1的平方以及x2的p值

247
00:08:35,660 --> 00:08:36,830
sigma squared 1 and p
参数化的x1的p

248
00:08:37,120 --> 00:08:38,130
of x2, parametrized by mu
被参数化的mu2

249
00:08:38,230 --> 00:08:39,050
2 and sigma squared 2, that
和σ2的平方

250
00:08:39,190 --> 00:08:41,360
would look like these two distributions over here.
看起来像在这里的两个分布

251
00:08:42,650 --> 00:08:44,280
And, turns out that
其实是

252
00:08:44,480 --> 00:08:45,960
if were to plot of p
如果绘制x的p的图像

253
00:08:46,210 --> 00:08:47,540
of x, right, which
那么就会看到

254
00:08:47,710 --> 00:08:49,000
is the product of these two
是这两个的乘积

255
00:08:49,210 --> 00:08:50,450
things, you can actually get
事实上

256
00:08:50,800 --> 00:08:52,770
a surface plot that looks like this.
你已经得到了一个这样的的表面图像

257
00:08:53,360 --> 00:08:54,370
This is a plot of p
这是

258
00:08:54,640 --> 00:08:55,920
of x, where the height
x的p值的图像

259
00:08:56,390 --> 00:08:57,730
above of this, where the
其高度比这个高

260
00:08:57,830 --> 00:08:58,950
height of this surface at
这个面的高度

261
00:08:58,990 --> 00:09:01,360
a particular point, so given a
在一个特别的点上

262
00:09:01,470 --> 00:09:03,670
particular x1 x2
给出一个特别的X1和X2的值

263
00:09:03,930 --> 00:09:05,640
values of x2 if
如果

264
00:09:05,800 --> 00:09:07,830
x1 equals 2, x equal 2, that's this point.
x1等于2 x等于2 那么就是这个点

265
00:09:08,510 --> 00:09:09,450
And the height of this 3-D
在此处的的3-D表面图

266
00:09:09,710 --> 00:09:11,280
surface here, that's p
那里是x的p值

267
00:09:13,020 --> 00:09:14,420
of x. So p of x, that is the height
是这个图的高度

268
00:09:14,710 --> 00:09:16,220
of this plot, is
从表面上看

269
00:09:16,340 --> 00:09:17,520
literally just p of x1
这个x1的p值是高度

270
00:09:18,640 --> 00:09:20,010
parametrized by mu 1 sigma
同时x1被mu1

271
00:09:20,290 --> 00:09:22,540
squared 1, times p
σ1的平方

272
00:09:23,200 --> 00:09:25,050
of x2 parametrized by
乘x2的p值

273
00:09:25,120 --> 00:09:27,530
mu 2 sigma squared 2.
被mu2以及σ2的平方参数化

274
00:09:27,720 --> 00:09:29,180
Now, so this is
现在

275
00:09:29,320 --> 00:09:31,400
how we fit the parameters to this data.
我们便得到了这组数据的合适的参数值

276
00:09:31,930 --> 00:09:32,950
Let's see if we have a couple of new examples.
让我们看看我们是否有了很多新的案例

277
00:09:33,530 --> 00:09:35,090
Maybe I have a new example there.
或许在这里我们有了一个新案例

278
00:09:36,700 --> 00:09:38,340
Is this an anomaly or not?
这个案例是否异常

279
00:09:38,550 --> 00:09:39,220
Or, maybe I have a different
或许我现在有了一个与以往不同的案例

280
00:09:39,570 --> 00:09:41,860
example, maybe I have a different second example over there.
或许在这里也有了一个与先前不同的第二案例

281
00:09:42,140 --> 00:09:43,400
So, is that an anomaly or not?
那是否有异常呢?

282
00:09:44,360 --> 00:09:47,050
They way we do that is, we
我们可以这么做

283
00:09:47,190 --> 00:09:48,470
would set some value for
我们给计算机无穷小量设置某个数值

284
00:09:48,620 --> 00:09:49,490
Epsilon, let's say I've chosen
我设置的

285
00:09:50,020 --> 00:09:51,220
Epsilon equals 0.02.
计算机无穷小量数值为0.02

286
00:09:51,980 --> 00:09:54,110
I'll say later how we choose Epsilon.
我会在后面讲到如何选取无穷小量的数值

287
00:09:55,180 --> 00:09:56,110
But let's take this first
不过 我们先讲这个第一个案例

288
00:09:56,540 --> 00:09:57,360
example, let me call this
让我把这个称为

289
00:09:57,500 --> 00:09:59,500
example X1 test.
案例X1测试

290
00:10:00,200 --> 00:10:01,010
And let me call the second example
同时

291
00:10:02,800 --> 00:10:03,900
X2 test.
称第二个案例为X2测试

292
00:10:04,780 --> 00:10:05,670
What we do is, we
我们现在要做的

293
00:10:05,820 --> 00:10:07,380
then compute p of
就是把X1测试中的的p值计算出来

294
00:10:07,540 --> 00:10:08,740
X1 test, so we use
之后

295
00:10:08,990 --> 00:10:10,400
this formula to compute it and
观察用这个公式计算出来数值

296
00:10:11,140 --> 00:10:12,760
this looks like a pretty large value.
不难发现这是一个相当大的数

297
00:10:13,250 --> 00:10:15,560
In particular, this is greater
特别地 这个值可能大于

298
00:10:15,920 --> 00:10:18,480
than, or greater than or equal to epsilon.
或者大于等于计算机的无穷小量

299
00:10:18,670 --> 00:10:19,670
And so this is a pretty
但其实相较于计算机的无穷小量

300
00:10:19,810 --> 00:10:21,290
high probability at least bigger
这个数值还是比较大的

301
00:10:21,490 --> 00:10:22,510
than epsilon, so we'll say that
所以我们也说

302
00:10:22,970 --> 00:10:24,490
X1 test is not an anomaly.
X1检测的结果不是异常

303
00:10:25,650 --> 00:10:27,370
Whereas, if you compute p of
然而 如果你计算x2检测的p值

304
00:10:27,440 --> 00:10:29,810
X2 test, well that is just a much smaller value.
会是一个更加小的数

305
00:10:30,170 --> 00:10:31,340
So this is less than
比计算机的无穷小量还要小

306
00:10:31,490 --> 00:10:32,490
epsilon and so we'll say
同时我们也会说

307
00:10:32,720 --> 00:10:34,400
that that is indeed an anomaly,
那确实是一个异常数值

308
00:10:34,860 --> 00:10:37,350
because it is much smaller than that epsilon that we then chose.
因为那已经远远小于了先前我们定义的计算机无穷小量的值

309
00:10:38,450 --> 00:10:39,950
And in fact, I'd improve it here.
但事实上 我们也可以对这个方法进行改良

310
00:10:40,460 --> 00:10:43,340
What this is really saying is that, you look through the 3d surface plot.
看这个三维表面图

311
00:10:44,660 --> 00:10:46,270
It's saying that all the
从图上不难看出

312
00:10:46,350 --> 00:10:47,940
values of x1 and x2
x1和x2的所有数值

313
00:10:48,210 --> 00:10:50,570
that have a high height
所在位置都是比较高的

314
00:10:50,810 --> 00:10:52,770
above the surface, corresponds to
尤其是

315
00:10:52,910 --> 00:10:55,160
an a non-anomalous example of an OK or normal example.
和一个比较好的或者一个正常案例比起来

316
00:10:55,970 --> 00:10:57,450
Whereas all the points far out
然而所有的点

317
00:10:57,640 --> 00:10:58,940
here, all the points out
距离这里都比较远

318
00:10:59,150 --> 00:11:00,460
here, all of those
所有的这些点

319
00:11:00,580 --> 00:11:01,740
points have very low
其概率值都比较小

320
00:11:01,910 --> 00:11:02,940
probability, so we are
所以

321
00:11:03,020 --> 00:11:04,310
going to flag those points
我们会把这些点标注成异常

322
00:11:04,620 --> 00:11:06,350
as anomalous, and so it's gonna define
并依此定义一些区域

323
00:11:06,760 --> 00:11:07,790
some region, that maybe looks
那么这么做之后 看起来可能是这样

324
00:11:08,000 --> 00:11:09,480
like this, so that everything
那些

325
00:11:09,810 --> 00:11:12,160
outside this, it flags
在这之外的

326
00:11:12,380 --> 00:11:12,580
as anomalous,
被标注成为异常

327
00:11:14,940 --> 00:11:16,260
whereas the things inside this
然后在里面的

328
00:11:16,770 --> 00:11:18,340
ellipse I just drew, if it
这个我刚画的椭圆形的这个

329
00:11:18,570 --> 00:11:21,320
considers okay, or non-anomalous, not anomalous examples.
如果它被认为是正常的 也可以说是非异常的案例

330
00:11:22,110 --> 00:11:24,040
And so this example x2
案例X2

331
00:11:24,250 --> 00:11:26,260
test lies outside
位于

332
00:11:26,650 --> 00:11:27,510
that region, and so it
那个区域之外

333
00:11:27,620 --> 00:11:30,280
has very small probability, and so we consider it an anomalous example.
那就有一个很小的概率 并且我们认为它是一个异常的案例

334
00:11:31,400 --> 00:11:32,990
In this video we talked about how to
在本节视频中

335
00:11:33,460 --> 00:11:35,440
estimate p of x, the probability of
我们谈到了如何估计x的p值

336
00:11:35,590 --> 00:11:36,840
x, for the purpose of
x的概率值

337
00:11:36,930 --> 00:11:38,740
developing an anomaly detection algorithm.
以开发出一种异常检测的算法

338
00:11:39,880 --> 00:11:40,890
And in this video, we also
在本节视频中

339
00:11:41,260 --> 00:11:42,970
stepped through an entire process
我们使用给出的数据集

340
00:11:43,830 --> 00:11:45,090
of giving data set, we
将整个操作流程都一步步走了下来

341
00:11:45,340 --> 00:11:47,740
have, fitting the parameters, doing parameter estimations.
我们找到了和合适的参数值并得到了估计的参数值

342
00:11:48,370 --> 00:11:50,570
We get mu and sigma parameters, and
我们得到了mu和σ的参数

343
00:11:50,700 --> 00:11:52,180
then taking new examples and deciding
然后对这些新的案例进行使用

344
00:11:52,740 --> 00:11:54,110
if the new examples are anomalous or not.
判断这些新的案例是不是有异常

345
00:11:55,490 --> 00:11:56,800
In the next few videos we
在接下来的几段视频中

346
00:11:56,880 --> 00:11:58,580
will delve deeper into this algorithm,
我们将更加深入地挖掘这个算法的内含

347
00:11:58,980 --> 00:11:59,930
and talk a bit more
此外

348
00:12:00,230 --> 00:12:02,310
about how to actually get this to work well.
我们也会说道如何更好地将这个算法投入实际的生产和工作中

