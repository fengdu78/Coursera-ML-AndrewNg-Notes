1
00:00:00,200 --> 00:00:03,878
You now know about linear regression with multiple variables.
你现在了解了多变量的线性回归
(字幕整理：中国海洋大学 黄海广,haiguang2000@qq.com )

2
00:00:03,910 --> 00:00:05,185
In this video, I wanna tell
在本段视频中 我想告诉你

3
00:00:05,185 --> 00:00:06,369
you a bit about the choice
一些用来

4
00:00:06,380 --> 00:00:07,830
of features that you have and
选择特征的方法以及

5
00:00:07,830 --> 00:00:09,742
how you can get different learning
如何得到不同的学习算法

6
00:00:09,750 --> 00:00:11,477
algorithm, sometimes very powerful
当选择了合适的特征后

7
00:00:11,477 --> 00:00:13,803
ones by choosing appropriate features.
这些算法往往是非常有效的

8
00:00:13,810 --> 00:00:15,229
And in particular I also want
另外 我也想

9
00:00:15,229 --> 00:00:17,826
to tell you about polynomial regression allows
给你们讲一讲多项式回归

10
00:00:17,826 --> 00:00:19,535
you to use the machinery of
它使得你们能够使用

11
00:00:19,535 --> 00:00:21,247
linear regression to fit very
线性回归的方法来拟合

12
00:00:21,247 --> 00:00:25,060
complicated, even very non-linear functions.
非常复杂的函数 甚至是非线性函数

13
00:00:25,690 --> 00:00:28,827
Let's take the example of predicting the price of the house.
以预测房价为例

14
00:00:29,300 --> 00:00:31,147
Suppose you have two features,
假设你有两个特征

15
00:00:31,147 --> 00:00:33,805
the frontage of house and the depth of the house.
分别是房子临街的宽度和垂直宽度

16
00:00:33,805 --> 00:00:35,428
So, here's the picture of the house we're trying to sell.
这就是我们想要卖出的房子的图片

17
00:00:35,428 --> 00:00:37,264
So, the frontage is
临街宽度

18
00:00:37,264 --> 00:00:40,103
defined as this distance
被定义为这个距离

19
00:00:40,103 --> 00:00:43,009
is basically the width
其实就是它的宽度

20
00:00:43,009 --> 00:00:44,949
or the length of
或者说是

21
00:00:44,960 --> 00:00:46,652
how wide your lot
你拥有的土地的宽度

22
00:00:46,652 --> 00:00:47,994
is if this that you
如果这块地都是你的的话

23
00:00:48,020 --> 00:00:49,468
own, and the depth
而这所房子的

24
00:00:49,500 --> 00:00:53,120
of the house is how
纵向深度就是

25
00:00:53,130 --> 00:00:54,758
deep your property is, so
你的房子的深度

26
00:00:54,770 --> 00:00:57,992
there's a frontage, there's a depth.
这是正面的宽度 这是深度

27
00:00:57,992 --> 00:00:59,858
called frontage and depth.
我们称之为临街宽度和纵深

28
00:00:59,858 --> 00:01:01,355
You might build a linear regression
你可能会 像这样 建立一个

29
00:01:01,360 --> 00:01:04,163
model like this where frontage
线性回归模型 其中临街宽度

30
00:01:04,180 --> 00:01:06,062
is your first feature x1 and
是你的第一个特征x1

31
00:01:06,062 --> 00:01:07,535
and depth is your second
纵深是你的第二个

32
00:01:07,535 --> 00:01:10,169
feature x2, but when you're
特征x2 但当我们在

33
00:01:10,169 --> 00:01:11,772
applying linear regression, you don't
运用线性回归时

34
00:01:11,772 --> 00:01:13,342
necessarily have to use
你不一定非要直接用

35
00:01:13,342 --> 00:01:16,607
just the features x1 and x2 that you're given.
给出的 x1 和 x2 作为特征

36
00:01:16,610 --> 00:01:20,531
What you can do is actually create new features by yourself.
其实你可以自己创造新的特征

37
00:01:20,531 --> 00:01:21,709
So, if I want to predict
因此 如果我要预测

38
00:01:21,710 --> 00:01:22,895
the price of a house, what I
房子的价格

39
00:01:22,895 --> 00:01:24,840
might do instead is decide
我真正要需做的 也许是

40
00:01:24,850 --> 00:01:27,468
that what really determines
确定真正能够决定

41
00:01:27,490 --> 00:01:29,133
the size of the house is
我房子大小 或者说我土地大小

42
00:01:29,133 --> 00:01:32,164
the area or the land area that I own.
的因素是什么

43
00:01:32,190 --> 00:01:33,365
So, I might create a new feature.
因此 我可能会创造一个新的特征

44
00:01:33,380 --> 00:01:34,609
I'm just gonna call this feature
我称之为

45
00:01:34,609 --> 00:01:40,409
x which is frontage, times depth.
x 它是临街宽度与纵深的乘积

46
00:01:40,440 --> 00:01:42,404
This is a multiplication symbol.
这是一个乘法符号

47
00:01:42,404 --> 00:01:44,334
It's a frontage x depth because
它是临街宽度与纵深的乘积

48
00:01:44,334 --> 00:01:46,040
this is the land area
这得到的就是我拥有的土地的面积

49
00:01:46,090 --> 00:01:48,035
that I own and I might
然后 我可以把

50
00:01:48,035 --> 00:01:50,651
then select my hypothesis
假设选择为

51
00:01:50,710 --> 00:01:53,327
as that using just
使其只使用

52
00:01:53,350 --> 00:01:54,785
one feature which is my
一个特征 也就是我的

53
00:01:54,785 --> 00:01:57,430
land area, right?
土地的面积 对吧？

54
00:01:57,580 --> 00:01:58,939
Because the area of a
由于矩形面积的

55
00:01:58,940 --> 00:02:00,345
rectangle is you know,
计算方法是

56
00:02:00,345 --> 00:02:01,432
the product of the length
矩形长和宽相乘

57
00:02:01,460 --> 00:02:03,822
of the size So, depending
因此 这取决于

58
00:02:03,822 --> 00:02:05,253
on what insight you might have
你从什么样的角度

59
00:02:05,280 --> 00:02:07,481
into a particular problem, rather than
去审视一个特定的问题 而不是

60
00:02:07,490 --> 00:02:09,604
just taking the features [xx]
只是直接去使用临街宽度和纵深

61
00:02:09,620 --> 00:02:11,103
that we happen to have started
这两个我们只是碰巧在开始时

62
00:02:11,130 --> 00:02:13,489
off with, sometimes by defining
使用的特征 有时 通过定义

63
00:02:13,489 --> 00:02:16,771
new features you might actually get a better model.
新的特征 你确实会得到一个更好的模型

64
00:02:16,790 --> 00:02:18,163
Closely related to the
与选择特征的想法

65
00:02:18,163 --> 00:02:19,745
idea of choosing your features
密切相关的一个概念

66
00:02:19,745 --> 00:02:22,973
is this idea called polynomial regression.
被称为多项式回归(polynomial regression)

67
00:02:23,010 --> 00:02:26,868
Let's say you have a housing price data set that looks like this.
比方说 你有这样一个住房价格的数据集

68
00:02:26,880 --> 00:02:29,646
Then there are a few different models you might fit to this.
为了拟合它 可能会有多个不同的模型供选择

69
00:02:29,660 --> 00:02:32,587
One thing you could do is fit a quadratic model like this.
其中一个你可以选择的是像这样的二次模型

70
00:02:32,600 --> 00:02:35,598
It doesn't look like a straight line fits this data very well.
因为直线似乎并不能很好地拟合这些数据

71
00:02:35,598 --> 00:02:36,788
So maybe you want to fit
因此 也许你会想到

72
00:02:36,788 --> 00:02:38,408
a quadratic model like this
用这样的二次模型去拟合数据

73
00:02:38,420 --> 00:02:40,248
where you think the size, where
你可能会考量

74
00:02:40,248 --> 00:02:42,017
you think the price is a quadratic
是关于价格的一个二次函数

75
00:02:42,020 --> 00:02:43,956
function and maybe that'll
也许这样做

76
00:02:43,970 --> 00:02:45,018
give you, you know, a fit
会给你一个

77
00:02:45,020 --> 00:02:47,070
to the data that looks like that.
像这样的拟合结果

78
00:02:47,280 --> 00:02:48,560
But then you may decide that your
但是 然后你可能会觉得

79
00:02:48,570 --> 00:02:50,013
quadratic model doesn't make sense
二次函数的模型并不好用

80
00:02:50,013 --> 00:02:52,582
because of a quadratic function, eventually
因为 一个二次函数最终

81
00:02:52,582 --> 00:02:53,858
this function comes back down
会降回来

82
00:02:53,858 --> 00:02:55,591
and well, we don't think housing
而我们并不认为

83
00:02:55,600 --> 00:02:58,899
prices should go down when the size goes up too high.
房子的价格在高到一定程度后 会下降回来

84
00:02:58,970 --> 00:03:00,649
So then maybe we might
因此 也许我们会

85
00:03:00,650 --> 00:03:02,700
choose a different polynomial model
选择一个不同的多项式模型

86
00:03:02,700 --> 00:03:04,274
and choose to use instead a
并转而选择使用一个

87
00:03:04,290 --> 00:03:07,480
cubic function, and where
三次函数 在这里

88
00:03:07,480 --> 00:03:09,225
we have now a third-order term
现在我们有了一个三次的式子

89
00:03:09,225 --> 00:03:10,764
and we fit that, maybe
我们用它进行拟合

90
00:03:10,800 --> 00:03:12,367
we get this sort of
我们可能得到这样的模型

91
00:03:12,390 --> 00:03:13,907
model, and maybe the
也许这条绿色的线

92
00:03:13,910 --> 00:03:15,278
green line is a somewhat better fit
对这个数据集拟合得更好

93
00:03:15,278 --> 00:03:18,052
to the data cause it doesn't eventually come back down.
因为它不会在最后下降回来

94
00:03:18,052 --> 00:03:21,992
So how do we actually fit a model like this to our data?
那么 我们到底应该如何将模型与我们的数据进行拟合呢？

95
00:03:22,020 --> 00:03:23,868
Using the machinery of multivariant
使用多元

96
00:03:23,868 --> 00:03:27,059
linear regression, we can
线性回归的方法 我们可以

97
00:03:27,059 --> 00:03:30,692
do this with a pretty simple modification to our algorithm.
通过将我们的算法做一个非常简单的修改来实现它

98
00:03:30,692 --> 00:03:32,632
The form of the hypothesis we,
按照我们以前假设的形式

99
00:03:32,632 --> 00:03:34,217
we know how the fit
我们知道如何对

100
00:03:34,217 --> 00:03:35,782
looks like this, where we say
这样的模型进行拟合 其中

101
00:03:35,782 --> 00:03:37,612
H of x is theta zero
?θ(x) 等于 θ0

102
00:03:37,612 --> 00:03:41,608
plus theta one x one plus x two theta X3.
+θ1×x1 + θ2×x2 + θ3×x3

103
00:03:41,608 --> 00:03:42,775
And if we want to
那么 如果我们想

104
00:03:42,775 --> 00:03:45,220
fit this cubic model that
拟合这个三次模型

105
00:03:45,250 --> 00:03:47,239
I have boxed in green,
就是我用绿色方框框起来的这个

106
00:03:47,239 --> 00:03:48,940
what we're saying is that
现在我们讨论的是

107
00:03:48,940 --> 00:03:49,825
to predict the price of a
为了预测一栋房子的价格

108
00:03:49,825 --> 00:03:51,364
house, it's theta 0 plus theta
我们用 θ0 加 θ1

109
00:03:51,364 --> 00:03:53,056
1 times the size of the house
乘以房子的面积

110
00:03:53,056 --> 00:03:55,905
plus theta 2 times the square size of the house.
加上 θ2 乘以房子面积的平方

111
00:03:55,910 --> 00:03:58,974
So this term is equal to that term.
因此 这个式子与那个式子是相等的

112
00:03:58,974 --> 00:04:00,885
And then plus theta 3
然后再加 θ3

113
00:04:00,890 --> 00:04:02,343
times the cube of the
乘以

114
00:04:02,350 --> 00:04:05,302
size of the house raises that third term.
房子面积的立方

115
00:04:05,470 --> 00:04:06,967
In order to map these
为了将这两个定义

116
00:04:06,990 --> 00:04:08,668
two definitions to each other,
互相对应起来

117
00:04:08,668 --> 00:04:10,339
well, the natural way
为了做到这一点

118
00:04:10,339 --> 00:04:12,128
to do that is to set
我们自然想到了

119
00:04:12,150 --> 00:04:13,568
the first feature x one to
将 x1 特征设为

120
00:04:13,568 --> 00:04:15,320
be the size of the house, and
房子的面积

121
00:04:15,320 --> 00:04:16,721
set the second feature x two
将第二个特征 x2 设为

122
00:04:16,721 --> 00:04:17,766
to be the square of the size
房屋面积的平方

123
00:04:17,766 --> 00:04:20,400
of the house, and set the third feature x three to
将第三个特征 x3 设为

124
00:04:20,400 --> 00:04:22,780
be the cube of the size of the house.
房子面积的立方

125
00:04:22,800 --> 00:04:24,292
And, just by choosing my
那么 仅仅通过将

126
00:04:24,292 --> 00:04:26,311
three features this way and
这三个特征这样设置

127
00:04:26,311 --> 00:04:27,720
applying the machinery of linear
然后再应用线性回归的方法

128
00:04:27,720 --> 00:04:30,540
regression, I can fit this
我就可以拟合

129
00:04:30,540 --> 00:04:31,901
model and end up with
这个模型 并最终

130
00:04:31,901 --> 00:04:34,374
a cubic fit to my data.
将一个三次函数拟合到我的数据上

131
00:04:34,374 --> 00:04:35,523
I just want to point out one
我还想再说一件事

132
00:04:35,523 --> 00:04:36,799
more thing, which is that
那就是

133
00:04:36,800 --> 00:04:38,610
if you choose your features
如果你像这样选择特征

134
00:04:38,610 --> 00:04:40,925
like this, then feature scaling
那么特征的归一化

135
00:04:40,925 --> 00:04:43,688
becomes increasingly important.
就变得更重要了

136
00:04:44,130 --> 00:04:45,254
So if the size of the
因此 如果

137
00:04:45,254 --> 00:04:46,794
house ranges from one to
房子的大小范围在

138
00:04:46,800 --> 00:04:47,992
a thousand, so, you know,
1到1000之间 那么

139
00:04:47,992 --> 00:04:49,300
from one to a thousand square
比如说

140
00:04:49,310 --> 00:04:50,918
feet, say, then the size
从1到1000平方尺 那么

141
00:04:50,930 --> 00:04:52,175
squared of the house will
房子面积的平方

142
00:04:52,175 --> 00:04:54,519
range from one to one
的范围就是

143
00:04:54,520 --> 00:04:55,953
million, the square of
一到一百万 也就是

144
00:04:55,953 --> 00:04:58,468
a thousand, and your third
1000的平方 而你的第三个特征

145
00:04:58,490 --> 00:05:01,335
feature x cubed, excuse me
x的立方 抱歉

146
00:05:01,360 --> 00:05:03,106
you, your third feature x
你的第三个特征 x3

147
00:05:03,120 --> 00:05:04,732
three, which is the size
它是房子面积的

148
00:05:04,732 --> 00:05:05,941
cubed of the house, will range
立方 范围会扩大到

149
00:05:05,950 --> 00:05:07,478
from one two ten to
1到10的9次方

150
00:05:07,478 --> 00:05:09,311
the nine, and so these
因此

151
00:05:09,330 --> 00:05:10,955
three features take on very
这三个特征的范围

152
00:05:10,955 --> 00:05:13,459
different ranges of values, and
有很大的不同

153
00:05:13,490 --> 00:05:15,105
it's important to apply feature
因此 如果你使用梯度下降法

154
00:05:15,110 --> 00:05:16,509
scaling if you're using gradient
应用特征值的归一化是非常重要的

155
00:05:16,509 --> 00:05:18,554
descent to get them into
这样才能将他们的

156
00:05:18,554 --> 00:05:21,139
comparable ranges of values.
值的范围变得具有可比性

157
00:05:21,140 --> 00:05:23,243
Finally, here's one last example
最后 这里是最后一个例子

158
00:05:23,250 --> 00:05:25,138
of how you really have
关于如何使你

159
00:05:25,150 --> 00:05:29,056
broad choices in the features you use.
真正选择出要使用的特征

160
00:05:29,090 --> 00:05:30,446
Earlier we talked about how a
此前我们谈到

161
00:05:30,446 --> 00:05:31,559
quadratic model like this might
一个像这样的二次模型

162
00:05:31,559 --> 00:05:33,122
not be ideal because, you know,
并不是理想的 因为 你知道

163
00:05:33,122 --> 00:05:34,408
maybe a quadratic model fits the
也许一个二次模型能很好地拟合

164
00:05:34,408 --> 00:05:35,952
data okay, but the quadratic
这个数据 但二次

165
00:05:35,952 --> 00:05:37,514
function goes back down
函数最后会下降

166
00:05:37,514 --> 00:05:39,065
and we really don't want, right,
这是我们不希望的

167
00:05:39,070 --> 00:05:40,352
housing prices that go down,
就是住房价格往下走

168
00:05:40,352 --> 00:05:43,567
to predict that, as the size of housing freezes.
像预测的那样 出现房价的下降

169
00:05:43,567 --> 00:05:45,388
But rather than going to
但是 除了转而

170
00:05:45,388 --> 00:05:46,938
a cubic model there, you
建立一个三次模型以外

171
00:05:46,938 --> 00:05:48,389
have, maybe, other choices of
你也许有其他的选择

172
00:05:48,389 --> 00:05:50,798
features and there are many possible choices.
特征的方法 这里有很多可能的选项

173
00:05:50,800 --> 00:05:52,313
But just to give you another
但是给你另外一个

174
00:05:52,313 --> 00:05:53,691
example of a reasonable
合理的选择的例子

175
00:05:53,691 --> 00:05:55,620
choice, another reasonable choice
另一种合理的选择

176
00:05:55,620 --> 00:05:57,263
might be to say that the
可能是这样的

177
00:05:57,263 --> 00:05:58,832
price of a house is theta
一套房子的价格是

178
00:05:58,850 --> 00:05:59,992
zero plus theta one times
θ0 加 θ1 乘以

179
00:05:59,992 --> 00:06:01,264
the size, and then plus theta
房子的面积 然后

180
00:06:01,320 --> 00:06:03,625
two times the square root of the size, right?
加 θ2 乘以房子面积的平方根 可以吧？

181
00:06:03,630 --> 00:06:05,364
So the square root function is
平方根函数是

182
00:06:05,364 --> 00:06:08,110
this sort of function, and maybe
这样的一种函数

183
00:06:08,110 --> 00:06:09,318
there will be some value of theta
也许θ1 θ2 θ3

184
00:06:09,318 --> 00:06:11,355
one, theta two, theta three, that
中会有一些值

185
00:06:11,355 --> 00:06:14,049
will let you take this model
会捕捉到这个模型

186
00:06:14,080 --> 00:06:15,445
and, for the curve that looks
从而使得这个曲线看起来

187
00:06:15,445 --> 00:06:16,952
like that, and, you know,
是这样的

188
00:06:16,952 --> 00:06:19,500
goes up, but sort of flattens
趋势是上升的 但慢慢变得

189
00:06:19,520 --> 00:06:21,529
out a bit and doesn't ever
平缓一些 而且永远不会

190
00:06:21,540 --> 00:06:23,877
come back down.
下降回来

191
00:06:24,154 --> 00:06:26,584
And, so, by having insight into, in
因此 通过深入地研究

192
00:06:26,584 --> 00:06:27,630
this case, the shape of a
在这里我们研究了平方根

193
00:06:27,630 --> 00:06:30,952
square root function, and, into
函数的形状 并且

194
00:06:30,990 --> 00:06:32,555
the shape of the data, by choosing
更深入地了解了选择不同特征时数据的形状

195
00:06:32,555 --> 00:06:36,469
different features, you can sometimes get better models.
有时可以得到更好的模型

196
00:06:36,469 --> 00:06:39,026
In this video, we talked about polynomial regression.
在这段视频中 我们探讨了多项式回归

197
00:06:39,026 --> 00:06:40,672
That is, how to fit a
也就是 如何将一个

198
00:06:40,672 --> 00:06:42,298
polynomial, like a quadratic function,
多项式 如一个二次函数

199
00:06:42,298 --> 00:06:43,868
or a cubic function, to your data.
或一个三次函数拟合到你的数据上

200
00:06:43,868 --> 00:06:45,112
Was also throw out this idea,
除了这个方面

201
00:06:45,112 --> 00:06:46,640
that you have a choice in what
我们还讨论了

202
00:06:46,640 --> 00:06:47,732
features to use, such as
在使用特征时的选择性

203
00:06:47,748 --> 00:06:48,804
that instead of using
例如 我们不使用

204
00:06:48,804 --> 00:06:50,078
the frontish and the depth
房屋的临街宽度和纵深

205
00:06:50,078 --> 00:06:51,092
of the house, maybe, you can
也许 你可以

206
00:06:51,092 --> 00:06:53,133
multiply them together to get
把它们乘在一起 从而得到

207
00:06:53,133 --> 00:06:55,317
a feature that captures the land area of a house.
房子的土地面积这个特征

208
00:06:55,317 --> 00:06:57,551
In case this seems a little
实际上 这似乎有点

209
00:06:57,551 --> 00:06:58,895
bit bewildering, that with all
难以抉择 这里有这么多

210
00:06:58,896 --> 00:07:03,265
these different feature choices, so how do I decide what features to use.
不同的特征选择 我该如何决定使用什么特征呢

211
00:07:03,265 --> 00:07:04,594
Later in this class, we'll talk
在之后的课程中 我们将

212
00:07:04,594 --> 00:07:06,622
about some algorithms were automatically
探讨一些算法 它们能够

213
00:07:06,622 --> 00:07:08,083
choosing what features are used,
自动选择要使用什么特征

214
00:07:08,083 --> 00:07:09,466
so you can have an
因此 你可以使用一个算法

215
00:07:09,466 --> 00:07:10,611
algorithm look at the data
观察给出的数据

216
00:07:10,611 --> 00:07:12,040
and automatically choose for you
并自动为你选择

217
00:07:12,040 --> 00:07:13,357
whether you want to fit a
到底应该选择

218
00:07:13,357 --> 00:07:15,528
quadratic function, or a cubic function, or something else.
一个二次函数 或者一个三次函数 还是别的函数

219
00:07:15,528 --> 00:07:17,164
But, until we get to
但是 在我们

220
00:07:17,164 --> 00:07:18,764
those algorithms now I just
学到那种算法之前

221
00:07:18,764 --> 00:07:20,295
want you to be aware that
现在我希望你知道

222
00:07:20,295 --> 00:07:21,582
you have a choice in
你需要选择

223
00:07:21,582 --> 00:07:23,094
what features to use, and
使用什么特征

224
00:07:23,094 --> 00:07:25,256
by designing different features
并且通过设计不同的特征

225
00:07:25,256 --> 00:07:26,888
you can fit more complex functions
你能够用更复杂的函数

226
00:07:26,888 --> 00:07:28,156
your data then just fitting a
去拟合你的数据 而不是只用

227
00:07:28,156 --> 00:07:30,471
straight line to the data and
一条直线去拟合

228
00:07:30,471 --> 00:07:32,092
in particular you can put polynomial
特别是 你也可以使用多项式

229
00:07:32,092 --> 00:07:35,065
functions as well and sometimes
函数 有时候

230
00:07:35,065 --> 00:07:36,072
by appropriate insight into the
通过采取适当的角度来观察

231
00:07:36,072 --> 00:07:37,564
feature simply get a much
特征就可以

232
00:07:37,564 --> 00:07:40,020
better model for your data.
得到一个更符合你的数据的模型

